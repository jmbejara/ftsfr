@misc{,
title = {{Forecasting Sales by Exponentially Weighted Moving Averages on JSTOR}},
url = {https://www.jstor.org/stable/2627346?saml_data=eyJpbnN0aXR1dGlvbklkcyI6WyI2YWQ1YjI5Yy0zMWI2LTQ1NTAtOTc1NS0yMjk4MGM3NGU3ZmMiXSwic2FtbFRva2VuIjoiMTliMTU1NzMtMGY4OC00YjBmLTkzOTQtNzAwNjI2YmZkZDQzIn0&seq=1},
urldate = {2025-07-08}
}
@article{,
file = {:Users/jbejarano/Library/CloudStorage/Dropbox/my_mendeley/Unknown - 2013 - CASH-FlOW MATURITY AND RISK PREMIA IN CDS MARKETS.pdf:pdf},
title = {{CASH-FlOW MATURITY AND RISK PREMIA IN CDS MARKETS}},
year = {2013}
}
@article{Assimakopoulos2000,
abstract = {This paper presents a new univariate forecasting method. The method is based on the concept of modifying the local curvature of the time-series through a coefficient 'Theta' (the Greek letter $\theta$), that is applied directly to the second differences of the data. The resulting series that are created maintain the mean and the slope of the original data but not their curvatures. These new time series are named Theta-lines. Their primary qualitative characteristic is the improvement of the approximation of the long-term behavior of the data or the augmentation of the short-term features, depending on the value of the Theta coefficient. The proposed method decomposes the original time series into two or more different Theta-lines. These are extrapolated separately and the subsequent forecasts are combined. The simple combination of two Theta-lines, the Theta = 0 (straight line) and Theta = 2 (double local curves) was adopted in order to produce forecasts for the 3003 series of the M3 competition. The method performed well, particularly for monthly series and for microeconomic data. {\textcopyright} 2000 International Institute of Forecasters. Published by Elsevier Science B.V. All rights reserved.},
author = {Assimakopoulos, V. and Nikolopoulos, K.},
doi = {10.1016/S0169-2070(00)00066-2},
file = {:Users/jbejarano/Library/CloudStorage/Dropbox/my_mendeley/Assimakopoulos, Nikolopoulos - 2000 - The theta model a decomposition approach to forecasting.pdf:pdf},
issn = {0169-2070},
journal = {International Journal of Forecasting},
keywords = {M3-competition,Time series,Univariate forecasting method},
month = {oct},
number = {4},
pages = {521--530},
publisher = {Elsevier},
title = {{The theta model: a decomposition approach to forecasting}},
url = {https://www.sciencedirect.com/science/article/abs/pii/S0169207000000662?via%3Dihub},
volume = {16},
year = {2000}
}
@article{Barth2021,
abstract = {We document the rise and fall of an arbitrage trade among hedge funds known as the Treasury cash-futures basis trade. This trade exploited a fundamental disconnect between cash and futures prices of Treasuries. We show that in recent years a replicating portfolio of Treasury bills and futures has been overvalued relative to Treasury notes and bonds, creating an opportunity for arbitrageurs. Using regulatory datasets on hedge fund exposures and repo transactions, we are able to both identify these arbitrage positions and estimate their aggregate size. We show that the basis trade became popular among hedge funds following 2016, rising to make up as much as half of all hedge fund Treasury positions and around a quarter of dealers' repo lending. We present a model and empirical evidence that link the rise in the basis trade to broader developments in the Treasury market, and shows how the trade could contribute to financial instability. In March of 2020, many of the risks of the trade materialized as Treasury market illiquidity associated with the COVID-19 pandemic led to large sales of these basis trade positions among hedge funds. While Treasury market disruptions spurred hedge funds to sell Treasuries, the unwinding of the basis trade was likely a consequence rather than the primary cause of the stress. Prompt intervention by the Federal Reserve may have prevented the trade from accelerating the deterioration of Treasury market functioning. Our results underscore the importance of non-bank actors in the current structure of the Treasury market, and suggest this structure could create risks going forward.},
author = {Barth, Daniel and Kahn, R Jay and Alquist, Ron and Buckley, Amanda and Gleason, Katherine and Haggerty, Maryann and Kruttli, Mathias and Mccormick, Matthew and Rajan, Sriram and Schreft, Stacey and Yamarthy, Ram},
file = {:Users/jbejarano/Library/CloudStorage/Dropbox/my_mendeley/Barth et al. - 2021 - Hedge funds and the Treasury cash-futures disconnect.pdf:pdf},
journal = {uncipc.orgD Barth, RJ KahnOFR WP, 2021•uncipc.org},
keywords = {G12,G13,G23,Treasuries,basis trade,futures,hedge fund,liquidity JEL Codes: E43,repo,securities dealers},
title = {{Hedge funds and the Treasury cash-futures disconnect}},
url = {http://uncipc.org/wp-content/uploads/2021/05/Hedge_Funds_and_the_Treasury_Cash-Futures_Disconnect.pdf},
year = {2021}
}
@article{BorriLUISSAdrienVerdelhanMITSloan2023,
abstract = {2},
author = {{Borri LUISS Adrien Verdelhan MIT Sloan}, Nicola and Albuquerque, Rui and Andrade, Sandro and Arellano, Cristina and Baxter, Marianne and Engel, Charles and Gopinath, Gita and Gourio, Francois and {Carlos Hatchondo}, Juan and Hebden, James and Kollmann, Robert and Lorenzoni, Guido and Lustig, Hanno and Pan, Jun and Piazzesi, Monika and Schneider, Martin and Singleton, Ken and Ventura, Jaume and Warnock, Frank and Yue, Vivian},
file = {:Users/jbejarano/Library/CloudStorage/Dropbox/my_mendeley/Borri LUISS Adrien Verdelhan MIT Sloan et al. - 2023 - Sovereign Risk Premia.pdf:pdf},
keywords = {Sovereign risk,default risk,emerging markets},
title = {{Sovereign Risk Premia}},
url = {https://iris.luiss.it/handle/11385/5542},
year = {2023}
}
@article{Box2013,
abstract = {George Box was born in Gravesend, Kent on 18 October 1919 and, after being educated at grammar school, went to the local polytechnic to study chemistry. When the war intervened he was posted to the British Army Engineers to work as a laboratory assistant in a...},
author = {Box, George},
doi = {10.1057/9781137291264_6},
isbn = {978-1-137-29126-4},
journal = {A Very British Affair},
pages = {161--215},
publisher = {Palgrave Macmillan, London},
title = {{Box and Jenkins: Time Series Analysis, Forecasting and Control}},
url = {https://link.springer.com/chapter/10.1057/9781137291264_6},
year = {2013}
}
@book{Brown2004,
author = {Brown, RG},
title = {{Smoothing, forecasting and prediction of discrete time series}},
url = {https://books.google.com/books?hl=en&lr=&id=XXFNW_QaJYgC&oi=fnd&pg=PA1&dq=Smoothing,+Forecasting+and+Prediction+of+Discrete+Time+Series+Front+Cover+Robert+Goodell+Brown&ots=EP8dBWrbIc&sig=VQvwke5hTnmCIMvsMmoWcxtKmPU},
year = {2004}
}
@article{Challu2022,
abstract = {Recent progress in neural forecasting accelerated improvements in the performance of large-scale forecasting systems. Yet, long-horizon forecasting remains a very difficult task. Two common challenges afflicting the task are the volatility of the predictions and their computational complexity. We introduce N-HiTS, a model which addresses both challenges by incorporating novel hierarchical interpolation and multi-rate data sampling techniques. These techniques enable the proposed method to assemble its predictions sequentially, emphasizing components with different frequencies and scales while decomposing the input signal and synthesizing the forecast. We prove that the hierarchical interpolation technique can efficiently approximate arbitrarily long horizons in the presence of smoothness. Additionally, we conduct extensive large-scale dataset experiments from the long-horizon forecasting literature, demonstrating the advantages of our method over the state-of-the-art methods, where N-HiTS provides an average accuracy improvement of almost 20% over the latest Transformer architectures while reducing the computation time by an order of magnitude (50 times). Our code is available at bit.ly/3VA5DoT},
archivePrefix = {arXiv},
arxivId = {2201.12886},
author = {Challu, Cristian and Olivares, Kin G. and Oreshkin, Boris N. and Ramirez, Federico Garza and Mergenthaler-Canseco, Max and Dubrawski, Artur},
doi = {10.1609/aaai.v37i6.25854},
eprint = {2201.12886},
file = {:Users/jbejarano/Library/CloudStorage/Dropbox/my_mendeley/Challu et al. - 2022 - N-HiTS Neural Hierarchical Interpolation for Time Series Forecasting.pdf:pdf},
isbn = {9781577358800},
issn = {2159-5399},
journal = {Proceedings of the 37th AAAI Conference on Artificial Intelligence, AAAI 2023},
month = {jan},
pages = {6989--6997},
publisher = {AAAI Press},
title = {{N-HiTS: Neural Hierarchical Interpolation for Time Series Forecasting}},
url = {https://arxiv.org/pdf/2201.12886},
volume = {37},
year = {2022}
}
@article{Constantinides2013,
abstract = {We construct a panel of S&P 500 Index call and put option portfolios, daily adjusted to maintain targeted maturity, moneyness, and unitmarket beta, and testmulti-factor pricing models. The standard linear factor methodology is applicable because the monthly portfolio returns have low skewness and are close to normal. We hypothesize that any one of crisis-related factors incorporating price jumps, volatility jumps, and liquidity (along with themarket) explains the cross-sectional variation in returns. Our hypothesis is not rejected, even when the factor premia are constrained to equal the corresponding premia in the cross-section of equities. The alphas of short-maturity out-of-the-money puts become economically and statistically insignificant.},
author = {Constantinides, George M and Jackwerth, Jens Carsten and Savov, Alexi and Franke, Gu¨nter and Golez, Ben and Grundy, Bruce and Jones, Christopher and Koijen, Ralph and Ruenzi, Stefan and Yaron, Amir},
doi = {10.1093/RAPSTU/RAT004},
file = {:Users/jbejarano/Library/CloudStorage/Dropbox/my_mendeley/Constantinides et al. - 2013 - The Puzzle of Index Option Returns.pdf:pdf},
issn = {2045-9920},
journal = {The Review of Asset Pricing Studies},
month = {dec},
number = {2},
pages = {229--257},
publisher = {Oxford Academic},
title = {{The Puzzle of Index Option Returns}},
url = {https://dx.doi.org/10.1093/rapstu/rat004},
volume = {3},
year = {2013}
}
@article{Das2023a,
abstract = {Recent work has shown that simple linear models can outperform several Transformer based approaches in long term time-series forecasting. Motivated by this, we propose a Multi-layer Perceptron (MLP) based encoder-decoder model, Time-series Dense Encoder (TiDE), for long-term time-series forecasting that enjoys the simplicity and speed of linear models while also being able to handle covariates and non-linear dependencies. Theoretically, we prove that the simplest linear analogue of our model can achieve near optimal error rate for linear dynamical systems (LDS) under some assumptions. Empirically, we show that our method can match or outperform prior approaches on popular long-term time-series forecasting benchmarks while being 5-10x faster than the best Transformer based model.},
archivePrefix = {arXiv},
arxivId = {2304.08424},
author = {Das, Abhimanyu and Kong, Weihao and Leach, Andrew and Mathur, Shaan and Sen, Rajat and Yu, Rose},
eprint = {2304.08424},
file = {:Users/jbejarano/Library/CloudStorage/Dropbox/my_mendeley/Das et al. - 2023 - Long-term Forecasting with TiDE Time-series Dense Encoder.pdf:pdf},
issn = {28358856},
journal = {Transactions on Machine Learning Research},
month = {apr},
publisher = {Transactions on Machine Learning Research},
title = {{Long-term Forecasting with TiDE: Time-series Dense Encoder}},
url = {https://arxiv.org/pdf/2304.08424},
volume = {2023},
year = {2023}
}
@article{Das2023,
abstract = {Motivated by recent advances in large language models for Natural Language Processing (NLP), we design a time-series foundation model for forecasting whose out-of-the-box zero-shot performance on a variety of public datasets comes close to the accuracy of state-of-the-art supervised forecasting models for each individual dataset. Our model is based on pretraining a patched-decoder style attention model on a large time-series corpus, and can work well across different forecasting history lengths, prediction lengths and temporal granularities.},
archivePrefix = {arXiv},
arxivId = {2310.10688},
author = {Das, Abhimanyu and Kong, Weihao and Sen, Rajat and Zhou, Yichen},
eprint = {2310.10688},
file = {:Users/jbejarano/Library/CloudStorage/Dropbox/my_mendeley/Das et al. - 2023 - A decoder-only foundation model for time-series forecasting.pdf:pdf},
issn = {26403498},
journal = {Proceedings of Machine Learning Research},
month = {oct},
pages = {10148--10167},
publisher = {ML Research Press},
title = {{A decoder-only foundation model for time-series forecasting}},
url = {https://arxiv.org/pdf/2310.10688},
volume = {235},
year = {2023}
}
@article{DeLivera2011a,
abstract = {An innovations state space modeling framework is introduced for forecasting complex seasonal time series such as those with multiple seasonal periods, high-frequency seasonality, non-integer seasonality, and dual-calendar effects. The new framework incorporates Box-Cox transformations, Fourier representations with time varying coefficients, and ARMA error correction. Likelihood evaluation and analytical expressions for point forecasts and interval predictions under the assumption of Gaussian errors are derived, leading to a simple, comprehensive approach to forecasting complex seasonal time series. A key feature of the framework is that it relies on a new method that greatly reduces the computational burden in the maximum likelihood estimation. The modeling framework is useful for a broad range of applications, its versatility being illustrated in three empirical studies. In addition, the proposed trigonometric formulation is presented as a means of decomposing complex seasonal time series, and it is shown that this decomposition leads to the identification and extraction of seasonal components which are otherwise not apparent in the time series plot itself. {\textcopyright} 2011 American Statistical Association.},
author = {de Livera, Alysha M. and Hyndman, Rob J. and Snyder, Ralph D.},
doi = {10.1198/JASA.2011.TM09771;WEBSITE:WEBSITE:TFOPB;JOURNAL:JOURNAL:UASA18;PAGEGROUP:STRING:PUBLICATION},
issn = {01621459},
journal = {Journal of the American Statistical Association},
keywords = {Fourier series,Prediction intervals,Seasonality,State space models,Time series decomposition},
month = {dec},
number = {496},
pages = {1513--1527},
publisher = {Taylor & Francis},
title = {{Forecasting time series with complex seasonal patterns using exponential smoothing}},
url = {https://scholar.google.com/scholar_url?url=https://www.tandfonline.com/doi/pdf/10.1198/jasa.2011.tm09771%3Fcasa_token%3DSh2PcXcQZhIAAAAA:d_UpGdtoPvY2bJ3A4v72M98SxHDDDkBseNrhKVBzBA29KhNkCi3kaWnLuEYHimSJ_0Zl1GvrnYwuXA&hl=en&sa=T&oi=ucasa&ct=ucasa&ei=kZdtaNgOtcKJ6g-l48yxCg&scisig=AAZF9b-0pUKhE_B2Yqvyf0bIxmDy},
volume = {106},
year = {2011}
}
@article{DeLivera2011,
abstract = {An innovations state space modeling framework is introduced for forecasting complex seasonal time series such as those with multiple seasonal periods, high-frequency seasonality, non-integer seasonality, and dual-calendar effects. The new framework incorporates Box-Cox transformations, Fourier representations with time varying coefficients, and ARMA error correction. Likelihood evaluation and analytical expressions for point forecasts and interval predictions under the assumption of Gaussian errors are derived, leading to a simple, comprehensive approach to forecasting complex seasonal time series. A key feature of the framework is that it relies on a new method that greatly reduces the computational burden in the maximum likelihood estimation. The modeling framework is useful for a broad range of applications, its versatility being illustrated in three empirical studies. In addition, the proposed trigonometric formulation is presented as a means of decomposing complex seasonal time series, and it is shown that this decomposition leads to the identification and extraction of seasonal components which are otherwise not apparent in the time series plot itself. {\textcopyright} 2011 American Statistical Association.},
author = {de Livera, Alysha M. and Hyndman, Rob J. and Snyder, Ralph D.},
doi = {10.1198/JASA.2011.TM09771;WEBSITE:WEBSITE:TFOPB;JOURNAL:JOURNAL:UASA18;PAGEGROUP:STRING:PUBLICATION},
issn = {01621459},
journal = {Journal of the American Statistical Association},
keywords = {Fourier series,Prediction intervals,Seasonality,State space models,Time series decomposition},
month = {dec},
number = {496},
pages = {1513--1527},
publisher = {Taylor & Francis},
title = {{Forecasting time series with complex seasonal patterns using exponential smoothing}},
url = {https://scholar.google.com/scholar_url?url=https://www.tandfonline.com/doi/pdf/10.1198/jasa.2011.tm09771%3Fcasa_token%3D4AUStFzZ0GQAAAAA:9Oaz4lzbfspHyUJ4xpB1wXnUtnAfIoJyeX99bNofLZd9vBNOrSwe4QxAs_j7oaABsDr-3ui-bKsbTg&hl=en&sa=T&oi=ucasa&ct=ucasa&ei=AjBtaK_},
volume = {106},
year = {2011}
}
@article{Drechsler2017,
abstract = {We present a new channel for the transmission of monetary policy, the deposits channel. We show that when the Fed funds rate rises, banks widen the spreads they charge on deposits, and deposits flow out of the banking system. We present a model where this is due to market power in deposit markets. Consistent with the market power mechanism, deposit spreads increase more and deposits flow out more in concentrated markets. This is true even when we control for lending opportunities by only comparing different branches of the same bank. Since deposits are the main source of liquid assets for households, the deposits channel can explain the observed strong relationship between the liquidity premium and the Fed funds rate. Since deposits are also a uniquely stable funding source for banks, the deposits channel impacts bank lending. When the Fed funds rate rises, banks that raise deposits in concentrated markets contract their lending by more than other banks. Our estimates imply that the deposits channel can account for the entire transmission of monetary policy through bank balance sheets. JEL Codes: E52, E58, G12, G21.},
author = {Drechsler, Itamar and Savov, Alexi and Schnabl, Philipp},
doi = {10.1093/QJE/QJX019},
file = {:Users/jbejarano/Library/CloudStorage/Dropbox/my_mendeley/Drechsler, Savov, Schnabl - 2017 - The Deposits Channel of Monetary Policy.pdf:pdf},
issn = {0033-5533},
journal = {The Quarterly Journal of Economics},
month = {nov},
number = {4},
pages = {1819--1876},
publisher = {Oxford Academic},
title = {{The Deposits Channel of Monetary Policy}},
url = {https://dx.doi.org/10.1093/qje/qjx019},
volume = {132},
year = {2017}
}
@article{Du2023,
abstract = {We document a regime change in the Treasury market post-Global Financial Crisis (GFC): dealers switched from net short to net long Treasury bonds. We construct “net-long” and “net-short” curves that account for balance sheet and financing costs, and show that actual yields moved from the net short curve pre-GFC to the net long curve post-GFC. Our theory shows the regime shift caused negative swap spreads and co-movement among swap spreads, dealer positions, and covered-interest-parity violations. Furthermore, the effects of various monetary and regulatory policies are regime-dependent. We highlight Treasury supply as a plausible driver of this regime shift.},
author = {Du, Wenxin and H{\'{e}}bert, Benjamin and Li, Wenhao},
doi = {10.1016/J.JFINECO.2023.103722},
file = {:Users/jbejarano/Library/CloudStorage/Dropbox/my_mendeley/Du, H{\'{e}}bert, Li - 2023 - Intermediary balance sheets and the treasury yield curve.pdf:pdf},
issn = {0304-405X},
journal = {Journal of Financial Economics},
keywords = {Arbitrage,Covered interest parity,Intermediary asset pricing,Treasury bonds},
month = {dec},
number = {3},
pages = {103722},
publisher = {North-Holland},
title = {{Intermediary balance sheets and the treasury yield curve}},
url = {https://www.sciencedirect.com/science/article/pii/S0304405X23001629?casa_token=_wxgX9DeZS0AAAAA:rcSOjn22URbWm0GFi-xlPzzAatt7LuJE66AzytGlUBGp3Lt_dLf3jG30pMfJWidKHBdrFNRNGA},
volume = {150},
year = {2023}
}
@article{Duffie1999,
abstract = {This review of the pricing of credit swaps, a form of derivative security that can be viewed as default insurance on loans or bonds, begins with a description of the credit swap contract, turns to pricing by reference to spreads over the risk-free rate of par floating-rate bonds of the same quality, and then considers model-based pricing. The role of asset swap spreads as a reference for pricing credit swaps is also considered.},
author = {Duffie, Darrell},
doi = {10.2469/FAJ.V55.N1.2243;WEBSITE:WEBSITE:TFOPB;PAGEGROUP:STRING:PUBLICATION},
issn = {0015198X},
journal = {Financial Analysts Journal},
number = {1},
pages = {73--87},
publisher = {CFA Institute},
title = {{Credit Swap Valuation}},
url = {https://www.tandfonline.com/doi/abs/10.2469/faj.v55.n1.2243},
volume = {55},
year = {1999}
}
@article{Fama1993,
abstract = {This paper identifies five common risk factors in the returns on stocks and bonds. There are three stock-market factors: an overall market factor and factors related to firm size and book-to-market equity. There are two bond-market factors, related to maturity and default risks. Stock returns have shared variation due to the stock-market factors, and they are linked to bond returns through shared variation in the bond-market factors. Except for low-grade corporates, the bond-market factors capture the common variation in bond returns. Most important, the five factors seem to explain average returns on stocks and bonds. {\textcopyright} 1993.},
author = {Fama, Eugene F. and French, Kenneth R.},
doi = {10.1016/0304-405X(93)90023-5},
file = {:Users/jbejarano/Library/CloudStorage/Dropbox/my_mendeley/Fama, French - 1993 - Common risk factors in the returns on stocks and bonds.pdf:pdf},
issn = {0304-405X},
journal = {Journal of Financial Economics},
month = {feb},
number = {1},
pages = {3--56},
publisher = {North-Holland},
title = {{Common risk factors in the returns on stocks and bonds}},
url = {https://www.sciencedirect.com/science/article/abs/pii/0304405X93900235},
volume = {33},
year = {1993}
}
@article{Fleckenstein2020,
abstract = {A long-standing asset pricing puzzle is that the funding rates in derivatives contracts often differ from those in cash markets. We propose that the cost of renting intermediary balance sheet space may help resolve this puzzle. We study a persistent basis in what is arguably the largest derivatives market, namely, the interest rate futures market. This basis is strongly related to exogenous measures of intermediary balance sheet usage and proxies for the balance sheet costs imposed by debt overhang problems and capital regulation. These results extend to the cash derivatives bases documented in many of the other largest financial markets.},
author = {Fleckenstein, Matthias and Longstaff, Francis A.},
doi = {10.1093/RFS/HHAA033},
file = {:Users/jbejarano/Library/CloudStorage/Dropbox/my_mendeley/Fleckenstein, Longstaff - 2020 - Renting Balance Sheet Space Intermediary Balance Sheet Rental Costs and the Valuation of Derivatives.pdf:pdf},
issn = {0893-9454},
journal = {The Review of Financial Studies},
month = {nov},
number = {11},
pages = {5051--5091},
publisher = {Oxford Academic},
title = {{Renting Balance Sheet Space: Intermediary Balance Sheet Rental Costs and the Valuation of Derivatives}},
url = {https://dx.doi.org/10.1093/rfs/hhaa033},
volume = {33},
year = {2020}
}
@book{Goodfellow2016,
author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
isbn = {0262035618},
publisher = {The MIT press},
title = {{Deep Learning}},
url = {http://www.deeplearningbook.org},
year = {2016}
}
@article{Gurkaynak2010,
abstract = {For over ten years, the Treasury has issued index-linked debt. This paper describes the methodology for fitting a smoothed yield curve to these securities that is used at the Federal Reserve Board every day, and makes the estimates public. Comparison with the corresponding nominal yield curve allows measures of inflation compensation to be computed. We discuss the interpretation of inflation compensation, and provide evidence that it is not a pure measure of inflation expectations being distorted by inflation risk premium and liquidity premium components. We attempt to estimate the TIPS liquidity premium and to extract underlying inflation expectations.},
author = {G{\"{u}}rkaynak, Refet S. and Sack, Brian and Wright, Jonathan H.},
doi = {10.1257/MAC.2.1.70},
issn = {1945-7707},
journal = {American Economic Journal: Macroeconomics},
keywords = {Debt Management,Deflation, Interest Rates: Determination, Term Str,Inflation,Price Level,Sovereign Debt},
month = {jan},
number = {1},
pages = {70--92},
publisher = {American Economic Association},
title = {{The TIPS Yield Curve and Inflation Compensation}},
volume = {2},
year = {2010}
}
@article{Gurkaynak2007,
abstract = {The discount function, which determines the value of all future nominal payments, is the most basic building block of finance and is usually inferred from the Treasury yield curve. It is therefore surprising that researchers and practitioners do not have available to them a long history of high-frequency yield curve estimates. This paper fills that void by making public the Treasury yield curve estimates of the Federal Reserve Board at a daily frequency from 1961 to the present. We use a well-known and simple smoothing method that is shown to fit the data very well. The resulting estimates can be used to compute yields or forward rates for any horizon. We hope that the data, which are posted on the website http://www.federalreserve.gov/pubs/feds/2006 and which will be updated quarterly, will provide a benchmark yield curve that will be useful to applied economists. {\textcopyright} 2007 Elsevier B.V. All rights reserved.},
author = {G{\"{u}}rkaynak, Refet S. and Sack, Brian and Wright, Jonathan H.},
doi = {10.1016/J.JMONECO.2007.06.029},
file = {:Users/jbejarano/Library/CloudStorage/Dropbox/my_mendeley/G{\"{u}}rkaynak, Sack, Wright - 2007 - The U.S. Treasury yield curve 1961 to the present.pdf:pdf},
issn = {0304-3932},
journal = {Journal of Monetary Economics},
keywords = {High-frequency data,On the run premia,Treasury market,Yield curve},
month = {nov},
number = {8},
pages = {2291--2304},
publisher = {North-Holland},
title = {{The U.S. Treasury yield curve: 1961 to the present}},
url = {https://www.sciencedirect.com/science/article/pii/S0304393207000840?casa_token=sBgB3KQh31UAAAAA:upQ35XDjoK8h0G5uyjbBCWVPDeBzRKcveoQNlhmktccNALNUE1rmmdirdUDj-fft3NcJivGQnw},
volume = {54},
year = {2007}
}
@article{He2017,
abstract = {We find that shocks to the equity capital ratio of financial intermediaries—Primary Dealer counterparties of the New York Federal Reserve—possess significant explanatory power for cross-sectional variation in expected returns. This is true not only for commonly studied equity and government bond market portfolios, but also for other more sophisticated asset classes such as corporate and sovereign bonds, derivatives, commodities, and currencies. Our intermediary capital risk factor is strongly procyclical, implying countercyclical intermediary leverage. The price of risk for intermediary capital shocks is consistently positive and of similar magnitude when estimated separately for individual asset classes, suggesting that financial intermediaries are marginal investors in many markets and hence key to understanding asset prices.},
author = {He, Zhiguo and Kelly, Bryan and Manela, Asaf},
doi = {10.1016/J.JFINECO.2017.08.002},
file = {:Users/jbejarano/Library/CloudStorage/Dropbox/my_mendeley/He, Kelly, Manela - 2017 - Intermediary asset pricing New evidence from many asset classes(2).pdf:pdf},
issn = {0304-405X},
journal = {Journal of Financial Economics},
keywords = {Intermediary capital,Leverage cycles,Primary dealers,Sophisticated asset classes},
month = {oct},
number = {1},
pages = {1--35},
publisher = {North-Holland},
title = {{Intermediary asset pricing: New evidence from many asset classes}},
volume = {126},
year = {2017}
}
@article{Jermann2020,
abstract = {Since October 2008, fixed rates for interest rate swaps with a 30-year maturity have been mostly below Treasury rates with the same maturity. Under standard assumptions, this implies the existence of arbitrage opportunities. This paper presents a model for pricing interest rate swaps, where frictions for holding bonds limit arbitrage. I analytically show that negative swap spreads should not be surprising. In the calibrated model, swap spreads can reasonably match empirical counterparts without the need for large demand imbalances in the swap market. Empirical evidence is consistent with the relation between term spreads and swap spreads in the model. Received April 16, 2017; editorial decision Januray 3, 2019 by Editor Stijn Van Nieuwerburgh.},
author = {Jermann, Urban J.},
doi = {10.1093/RFS/HHZ030},
file = {:Users/jbejarano/Library/CloudStorage/Dropbox/my_mendeley/Jermann - 2020 - Negative Swap Spreads and Limited Arbitrage(2).pdf:pdf},
issn = {0893-9454},
journal = {The Review of Financial Studies},
month = {jan},
number = {1},
pages = {212--238},
publisher = {Oxford Academic},
title = {{Negative Swap Spreads and Limited Arbitrage}},
url = {https://dx.doi.org/10.1093/rfs/hhz030},
volume = {33},
year = {2020}
}
@article{Lettau2014,
abstract = {The downside risk capital asset pricing model (DR-CAPM) can price the cross section of currency returns. The market-beta differential between high and low interest rate currencies is higher conditional on bad market returns, when the market price of risk is also high, than it is conditional on good market returns. Correctly accounting for this variation is crucial for the empirical performance of the model. The DR-CAPM can jointly rationalize the cross section of equity, equity index options, commodity, sovereign bond and currency returns, thus offering a unified risk view of these asset classes. In contrast, popular models that have been developed for a specific asset class fail to jointly price other asset classes.},
author = {Lettau, Martin and Maggiori, Matteo and Weber, Michael},
doi = {10.1016/J.JFINECO.2014.07.001},
file = {:Users/jbejarano/Library/CloudStorage/Dropbox/my_mendeley/Lettau, Maggiori, Weber - 2014 - Conditional risk premia in currency markets and other asset classes.pdf:pdf},
issn = {0304-405X},
journal = {Journal of Financial Economics},
keywords = {Carry trade,Commodity basis,Downside risk,Equity cross section},
month = {nov},
number = {2},
pages = {197--225},
publisher = {North-Holland},
title = {{Conditional risk premia in currency markets and other asset classes}},
url = {https://www.sciencedirect.com/science/article/pii/S0304405X14001378?casa_token=I86SZLZWcW0AAAAA:hz3692U1muFtgjDPyxGqiYogHmZmE-_E_Bq6qx8n8TqNK4-VSaFSZ2r_QGYp28WOXRIOPxb7QQ},
volume = {114},
year = {2014}
}
@article{Lim2021,
abstract = {Multi-horizon forecasting often contains a complex mix of inputs – including static (i.e. time-invariant) covariates, known future inputs, and other exogenous time series that are only observed in the past – without any prior information on how they interact with the target. Several deep learning methods have been proposed, but they are typically ‘black-box' models that do not shed light on how they use the full range of inputs present in practical scenarios. In this paper, we introduce the Temporal Fusion Transformer (TFT) – a novel attention-based architecture that combines high-performance multi-horizon forecasting with interpretable insights into temporal dynamics. To learn temporal relationships at different scales, TFT uses recurrent layers for local processing and interpretable self-attention layers for long-term dependencies. TFT utilizes specialized components to select relevant features and a series of gating layers to suppress unnecessary components, enabling high performance in a wide range of scenarios. On a variety of real-world datasets, we demonstrate significant performance improvements over existing benchmarks, and highlight three practical interpretability use cases of TFT.},
archivePrefix = {arXiv},
arxivId = {1912.09363},
author = {Lim, Bryan and Arık, Sercan and Loeff, Nicolas and Pfister, Tomas},
doi = {10.1016/j.ijforecast.2021.03.012},
eprint = {1912.09363},
file = {:Users/jbejarano/Library/CloudStorage/Dropbox/my_mendeley/Lim et al. - 2021 - Temporal Fusion Transformers for interpretable multi-horizon time series forecasting.pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {Attention mechanisms,Deep learning,Explainable AI,Interpretability,Multi-horizon forecasting,Time series},
month = {oct},
number = {4},
pages = {1748--1764},
publisher = {Elsevier B.V.},
title = {{Temporal Fusion Transformers for interpretable multi-horizon time series forecasting}},
url = {https://arxiv.org/pdf/1912.09363},
volume = {37},
year = {2021}
}
@article{Menkhoff2012,
abstract = {We investigate the relation between global foreign exchange (FX) volatility risk and the cross section of excess returns arising from popular strategies that borrow in low interest rate currencies and invest in high interest rate currencies, so-called "carry trades." We find that high interest rate currencies are negatively related to innovations in global FX volatility, and thus deliver low returns in times of unexpected high volatility, when low interest rate currencies provide a hedge by yielding positive returns. Furthermore, we show that volatility risk dominates liquidity risk and our volatility risk proxy also performs well for pricing returns of other portfolios. {\textcopyright} 2012 the American Finance Association.},
author = {Menkhoff, Lukas and Sarno, Lucio and Schmeling, Maik and Schrimpf, Andreas},
doi = {10.1111/J.1540-6261.2012.01728.X;PAGE:STRING:ARTICLE/CHAPTER},
file = {:Users/jbejarano/Library/CloudStorage/Dropbox/my_mendeley/Menkhoff et al. - 2012 - Carry Trades and Global Foreign Exchange Volatility.pdf:pdf},
issn = {00221082},
journal = {Journal of Finance},
month = {apr},
number = {2},
pages = {681--718},
publisher = {John Wiley & Sons, Ltd},
title = {{Carry Trades and Global Foreign Exchange Volatility}},
url = {/doi/pdf/10.1111/j.1540-6261.2012.01728.x https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1540-6261.2012.01728.x https://onlinelibrary.wiley.com/doi/10.1111/j.1540-6261.2012.01728.x},
volume = {67},
year = {2012}
}
@article{Nie2022,
abstract = {We propose an efficient design of Transformer-based models for multivariate time series forecasting and self-supervised representation learning. It is based on two key components: (i) segmentation of time series into subseries-level patches which are served as input tokens to Transformer; (ii) channel-independence where each channel contains a single univariate time series that shares the same embedding and Transformer weights across all the series. Patching design naturally has three-fold benefit: local semantic information is retained in the embedding; computation and memory usage of the attention maps are quadratically reduced given the same look-back window; and the model can attend longer history. Our channel-independent patch time series Transformer (PatchTST) can improve the long-term forecasting accuracy significantly when compared with that of SOTA Transformer-based models. We also apply our model to self-supervised pre-training tasks and attain excellent fine-tuning performance, which outperforms supervised training on large datasets. Transferring of masked pre-trained representation on one dataset to others also produces SOTA forecasting accuracy. Code is available at: https://github.com/yuqinie98/PatchTST.},
archivePrefix = {arXiv},
arxivId = {2211.14730},
author = {Nie, Yuqi and Nguyen, Nam H. and Sinthong, Phanwadee and Kalagnanam, Jayant},
eprint = {2211.14730},
file = {:Users/jbejarano/Library/CloudStorage/Dropbox/my_mendeley/Nie et al. - 2022 - A Time Series is Worth 64 Words Long-term Forecasting with Transformers.pdf:pdf},
journal = {11th International Conference on Learning Representations, ICLR 2023},
month = {nov},
publisher = {International Conference on Learning Representations, ICLR},
title = {{A Time Series is Worth 64 Words: Long-term Forecasting with Transformers}},
url = {https://arxiv.org/pdf/2211.14730},
year = {2022}
}
@article{Nozawa2017,
abstract = {I decompose the variation of credit spreads for corporate bonds into changing expected returns and changing expectation of credit losses. Using a log-linearized pricing identity and a vector autoregression applied to microlevel data from 1973 to 2011, I find that expected returns contribute to the cross-sectional variance of credit spreads nearly as much as expected credit loss does. However, most of the time-series variation in credit spreads for the market portfolio corresponds to risk premiums.},
author = {Nozawa, Yoshio},
doi = {10.1111/JOFI.12524;WGROUP:STRING:PUBLICATION},
file = {:Users/jbejarano/Library/CloudStorage/Dropbox/my_mendeley/Nozawa - 2017 - What Drives the Cross-Section of Credit Spreads A Variance Decomposition Approach.pdf:pdf},
issn = {15406261},
journal = {Journal of Finance},
month = {oct},
number = {5},
pages = {2045--2072},
publisher = {Blackwell Publishing Ltd},
title = {{What Drives the Cross-Section of Credit Spreads?: A Variance Decomposition Approach}},
url = {/doi/pdf/10.1111/jofi.12524 https://onlinelibrary.wiley.com/doi/abs/10.1111/jofi.12524 https://onlinelibrary.wiley.com/doi/10.1111/jofi.12524},
volume = {72},
year = {2017}
}
@article{Oord2016,
abstract = {This paper introduces WaveNet, a deep neural network for generating raw audio waveforms. The model is fully probabilistic and autoregressive, with the predictive distribution for each audio sample conditioned on all previous ones; nonetheless we show that it can be efficiently trained on data with tens of thousands of samples per second of audio. When applied to text-to-speech, it yields state-of-the-art performance, with human listeners rating it as significantly more natural sounding than the best parametric and concatenative systems for both English and Mandarin. A single WaveNet can capture the characteristics of many different speakers with equal fidelity, and can switch between them by conditioning on the speaker identity. When trained to model music, we find that it generates novel and often highly realistic musical fragments. We also show that it can be employed as a discriminative model, returning promising results for phoneme recognition.},
archivePrefix = {arXiv},
arxivId = {1609.03499},
author = {van den Oord, Aaron and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray},
eprint = {1609.03499},
file = {:Users/jbejarano/Library/CloudStorage/Dropbox/my_mendeley/Oord et al. - 2016 - WaveNet A Generative Model for Raw Audio.pdf:pdf},
month = {sep},
title = {{WaveNet: A Generative Model for Raw Audio}},
url = {https://arxiv.org/pdf/1609.03499},
year = {2016}
}
@inproceedings{Oreshkin2020,
abstract = {We focus on solving the univariate times series point forecasting problem using deep learning. We propose a deep neural architecture based on backward and forward residual links and a very deep stack of fully-connected layers. The architecture has a number of desirable properties, being interpretable, applicable without modification to a wide array of target domains, and fast to train. We test the proposed architecture on several well-known datasets, including M3, M4 and TOURISM competition datasets containing time series from diverse domains. We demonstrate state-of-the-art performance for two configurations of N-BEATS for all the datasets, improving forecast accuracy by 11% over a statistical benchmark and by 3% over last year's winner of the M4 competition, a domain-adjusted hand-crafted hybrid between neural network and statistical time series models. The first configuration of our model does not employ any time-series-specific components and its performance on heterogeneous datasets strongly suggests that, contrarily to received wisdom, deep learning primitives such as residual blocks are by themselves sufficient to solve a wide range of forecasting problems. Finally, we demonstrate how the proposed architecture can be augmented to provide outputs that are interpretable without considerable loss in accuracy.},
author = {Oreshkin, Boris N and Carpov, Dmitri and Chapados, Nicolas and {Bengio Mila}, Yoshua},
booktitle = {Eighth INTERNATIONAL CONFERENCE ON LEARNING REPRESENTATIONS},
file = {:Users/jbejarano/Library/CloudStorage/Dropbox/my_mendeley/Oreshkin et al. - 2020 - N-BEATS Neural basis expansion analysis for interpretable time series forecasting.pdf:pdf},
title = {{N-BEATS: Neural basis expansion analysis for interpretable time series forecasting}},
url = {https://iclr.cc/virtual_2020/poster_r1ecqn4YwB.html},
year = {2020}
}
@article{Prokhorenkova,
abstract = {This paper presents the key algorithmic techniques behind CatBoost, a new gradient boosting toolkit. Their combination leads to CatBoost outperforming other publicly available boosting implementations in terms of quality on a variety of datasets. Two critical algorithmic advances introduced in CatBoost are the implementation of ordered boosting, a permutation-driven alternative to the classic algorithm, and an innovative algorithm for processing categorical features. Both techniques were created to fight a prediction shift caused by a special kind of target leakage present in all currently existing implementations of gradient boosting algorithms. In this paper, we provide a detailed analysis of this problem and demonstrate that proposed algorithms solve it effectively, leading to excellent empirical results.},
author = {Prokhorenkova, Liudmila and Gusev, Gleb and Vorobev, Aleksandr and Dorogush, Anna Veronika and Gulin, Andrey},
doi = {10.5555/3327757.3327770},
file = {:Users/jbejarano/Library/CloudStorage/Dropbox/my_mendeley/Prokhorenkova et al. - 2018 - CatBoost unbiased boosting with categorical features.pdf:pdf},
title = {{CatBoost: unbiased boosting with categorical features}},
url = {https://dl.acm.org/doi/pdf/10.5555/3327757.3327770},
year = {2018}
}
@article{Ronn1989,
abstract = {This paper develops and tests arbitrage bounds for a combination of two option spread positions known as a box spread. This strategy involves the simultaneous use of four options and creates a position that is equivalent to riskless lending. The no-arbitrage conditions are compared to existing arbitrage bounds and are tested using Chicago Board Options Exchange data. Article published by Oxford University Press on behalf of the Society for Financial Studies in its journal, The Review of Financial Studies.},
author = {Ronn, Aimee Gerbarg and Ronn, Ehud I and Ronn, Aimee Gerbarg and Ronn, Ehud I},
file = {:Users/jbejarano/Library/CloudStorage/Dropbox/my_mendeley/Ronn et al. - 1989 - The Box Spread Arbitrage Conditions Theory, Tests, and Investment Strategies.pdf:pdf},
issn = {0893-9454},
journal = {The Review of Financial Studies},
number = {1},
pages = {91--108},
publisher = {Society for Financial Studies},
title = {{The Box Spread Arbitrage Conditions: Theory, Tests, and Investment Strategies}},
url = {https://econpapers.repec.org/RePEc:oup:rfinst:v:2:y:1989:i:1:p:91-108},
volume = {2},
year = {1989}
}
@article{Salinas2020,
abstract = {Probabilistic forecasting, i.e., estimating a time series' future probability distribution given its past, is a key enabler for optimizing business processes. In retail businesses, for example, probabilistic demand forecasts are crucial for having the right inventory available at the right time and in the right place. This paper proposes DeepAR, a methodology for producing accurate probabilistic forecasts, based on training an autoregressive recurrent neural network model on a large number of related time series. We demonstrate how the application of deep learning techniques to forecasting can overcome many of the challenges that are faced by widely-used classical approaches to the problem. By means of extensive empirical evaluations on several real-world forecasting datasets, we show that our methodology produces more accurate forecasts than other state-of-the-art methods, while requiring minimal manual work.},
archivePrefix = {arXiv},
arxivId = {1704.04110},
author = {Salinas, David and Flunkert, Valentin and Gasthaus, Jan and Januschowski, Tim},
doi = {10.1016/J.IJFORECAST.2019.07.001},
eprint = {1704.04110},
file = {:Users/jbejarano/Library/CloudStorage/Dropbox/my_mendeley/Salinas et al. - 2020 - DeepAR Probabilistic forecasting with autoregressive recurrent networks.pdf:pdf},
issn = {0169-2070},
journal = {International Journal of Forecasting},
keywords = {Big data,Deep learning,Demand forecasting,Neural networks,Probabilistic forecasting},
month = {jul},
number = {3},
pages = {1181--1191},
publisher = {Elsevier},
title = {{DeepAR: Probabilistic forecasting with autoregressive recurrent networks}},
url = {https://www.sciencedirect.com/science/article/pii/S0169207019301888?via%3Dihub},
volume = {36},
year = {2020}
}
@article{Siriwardane2021,
abstract = {We use arbitrage activity in equity, fixed income, and foreign exchange markets to characterize the frictions and constraints facing intermediaries. The average pairwise correlation between the twenty-nine arbitrage spreads that we study is 22%. These low correlations are inconsistent with models in which an integrated intermediary sector faces a single constraint and sets all prices. We show that at least two types of segmentation drive arbitrage dynamics. First, funding is segmented-certain trades rely on specific funding sources so arbitrage spreads are sensitive to localized funding shocks. Second, balance sheets are segmented-intermediaries specialize in certain arbitrages so arbitrage spreads are sensitive to idiosyncratic balance sheet shocks. Our results suggest specialization on both the asset and liability sides of intermediary balance sheets is important for understanding their role in capital markets.},
author = {Siriwardane, Emil and Sunderam, Aditya and Wallen, Jonathan},
doi = {10.2139/SSRN.3960980},
file = {:Users/jbejarano/Library/CloudStorage/Dropbox/my_mendeley/Siriwardane, Sunderam, Wallen - 2021 - Segmented Arbitrage(3).pdf:pdf;:Users/jbejarano/Library/CloudStorage/Dropbox/my_mendeley/Siriwardane, Sunderam, Wallen - 2021 - Segmented Arbitrage(2).pdf:pdf},
journal = {Available at SSRN},
keywords = {Aditya Sunderam,Emil Siriwardane,Jonathan Wallen,SSRN,Segmented Arbitrage,arbitrage,intermediary-based asset pricing,segmentation},
month = {nov},
publisher = {Elsevier BV},
title = {{Segmented Arbitrage}},
url = {https://papers.ssrn.com/abstract=3960980},
volume = {3960980},
year = {2021}
}
@article{Taylor2018,
abstract = {Forecasting is a common data science task that helps organizations with capacity planning, goal setting, and anomaly detection. Despite its importance, there are serious challenges associated with producing reliable and high-quality forecasts—especially when there are a variety of time series and analysts with expertise in time series modeling are relatively rare. To address these challenges, we describe a practical approach to forecasting “at scale” that combines configurable models with analyst-in-the-loop performance analysis. We propose a modular regression model with interpretable parameters that can be intuitively adjusted by analysts with domain knowledge about the time series. We describe performance analyses to compare and evaluate forecasting procedures, and automatically flag forecasts for manual review and adjustment. Tools that help analysts to use their expertise most effectively enable reliable, practical forecasting of business time series.},
author = {Taylor, Sean J. and Letham, Benjamin},
doi = {10.1080/00031305.2017.1380080},
issn = {15372731},
journal = {The American Statistician},
keywords = {Nonlinear regression,Statistical practice,Time series},
month = {jan},
number = {1},
pages = {37--45},
publisher = {American Statistical Association},
title = {{Forecasting at scale}},
url = {https://www.tandfonline.com/doi/abs/10.1080/00031305.2017.1380080?casa_token=hB5TwMQ_avsAAAAA:JMn1fmRcEzQNiblxcb7A6xM5Woi1AT8hWc6j1toYOmfFdTcT5OGZRbBD3EtGgT4PlinkzQFg8b4XCg},
volume = {72},
year = {2018}
}
@article{Trapero2015,
abstract = {Shorter product life cycles and aggressive marketing, among other factors, have increased the complexity of sales forecasting. Forecasts are often produced using a Forecasting Support System that integrates univariate statistical forecasting with managerial judgment. Forecasting sales under promotional activity is one of the main reasons to use expert judgment. Alternatively, one can replace expert adjustments by regression models whose exogenous inputs are promotion features (price, display, etc). However, these regression models may have large dimensionality as well as multicollinearity issues. We propose a novel promotional model that overcomes these limitations. It combines Principal Component Analysis to reduce the dimensionality of the problem and automatically identifies the demand dynamics. For items with limited history, the proposed model is capable of providing promotional forecasts by selectively pooling information across established products. The performance of the model is compared against forecasts provided by experts and statistical benchmarks, on weekly data; outperforming both substantially.},
author = {Trapero, Juan R. and Kourentzes, Nikolaos and Fildes, Robert},
doi = {10.1057/JORS.2013.174;WGROUP:STRING:PUBLICATION},
issn = {14769360},
journal = {Journal of the Operational Research Society},
keywords = {Promotional modelling,demand forecasting,judgmental adjustments,principal components analysis},
month = {feb},
number = {2},
pages = {299--307},
publisher = {Palgrave Macmillan Ltd.},
title = {{On the identification of sales forecasting models in the presence of promotions}},
url = {https://www.tandfonline.com/doi/abs/10.1057/jors.2013.174},
volume = {66},
year = {2015}
}
@article{Vaswani2017,
abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.},
author = {Vaswani, Ashish and Brain, Google and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
file = {:Users/jbejarano/Library/CloudStorage/Dropbox/my_mendeley/Vaswani et al. - 2017 - Attention is All you Need.pdf:pdf},
journal = {Advances in Neural Information Processing Systems},
title = {{Attention is All you Need}},
volume = {30},
year = {2017}
}
@article{Wu2021,
abstract = {Extending the forecasting time is a critical demand for real applications, such as extreme weather early warning and long-term energy consumption planning. This paper studies the long-term forecasting problem of time series. Prior Transformer-based models adopt various self-attention mechanisms to discover the long-range dependencies. However, intricate temporal patterns of the long-term future prohibit the model from finding reliable dependencies. Also, Transformers have to adopt the sparse versions of point-wise self-attentions for long series efficiency, resulting in the information utilization bottleneck. Going beyond Transformers, we design Autoformer as a novel decomposition architecture with an Auto-Correlation mechanism. We break with the pre-processing convention of series decomposition and renovate it as a basic inner block of deep models. This design empowers Autoformer with progressive decomposition capacities for complex time series. Further, inspired by the stochastic process theory, we design the Auto-Correlation mechanism based on the series periodicity, which conducts the dependencies discovery and representation aggregation at the sub-series level. Auto-Correlation outperforms self-attention in both efficiency and accuracy. In long-term forecasting, Autoformer yields state-of-the-art accuracy, with a 38% relative improvement on six benchmarks, covering five practical applications: energy, traffic, economics, weather and disease. Code is available at this repository: \url{https://github.com/thuml/Autoformer}.},
archivePrefix = {arXiv},
arxivId = {2106.13008},
author = {Wu, Haixu and Xu, Jiehui and Wang, Jianmin and Long, Mingsheng},
eprint = {2106.13008},
file = {:Users/jbejarano/Library/CloudStorage/Dropbox/my_mendeley/Wu et al. - 2021 - Autoformer Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting.pdf:pdf},
isbn = {9781713845393},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
month = {jun},
pages = {22419--22430},
publisher = {Neural information processing systems foundation},
title = {{Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting}},
url = {https://arxiv.org/pdf/2106.13008},
volume = {27},
year = {2021}
}
@article{Yang2013,
abstract = {I identify a "slope" factor in the cross section of commodity futures returns: high-basis commodity futures have higher loadings on this factor than low-basis commodity futures. Combined with a level factor (an index of commodity futures), this slope factor explains most of the average excess returns of commodity futures portfolios sorted by basis. More importantly, I find that this factor is significantly correlated with investment shocks, which represent the technological progress in producing new capital. I investigate a competitive dynamic equilibrium model of commodity production to endogenize this correlation. The model reproduces the cross-sectional futures returns and many asset pricing tests. {\textcopyright} 2013 Elsevier B.V.},
author = {Yang, Fan},
doi = {10.1016/J.JFINECO.2013.04.012},
file = {:Users/jbejarano/Library/CloudStorage/Dropbox/my_mendeley/Yang - 2013 - Investment shocks and the commodity basis spread.pdf:pdf},
issn = {0304-405X},
journal = {Journal of Financial Economics},
keywords = {Basis spread,Commodity futures,Investment shocks,Investment-based asset pricing},
month = {oct},
number = {1},
pages = {164--184},
publisher = {North-Holland},
title = {{Investment shocks and the commodity basis spread}},
url = {https://www.sciencedirect.com/science/article/pii/S0304405X13001360?casa_token=FYcuSZ3lD94AAAAA:BQBq-Ja8FB0JScYrNoQV_2LYSvB4pI_Tvdi5GGaf1juhcfNZ_033v8Hh-Cm-45UhSiL20fwoXw},
volume = {110},
year = {2013}
}
@article{Zeng2022,
abstract = {Recently, there has been a surge of Transformer-based solutions for the long-term time series forecasting (LTSF) task. Despite the growing performance over the past few years, we question the validity of this line of research in this work. Specifically, Transformers is arguably the most successful solution to extract the semantic correlations among the elements in a long sequence. However, in time series modeling, we are to extract the temporal relations in an ordered set of continuous points. While employing positional encoding and using tokens to embed sub-series in Transformers facilitate preserving some ordering information, the nature of the \emph{permutation-invariant} self-attention mechanism inevitably results in temporal information loss. To validate our claim, we introduce a set of embarrassingly simple one-layer linear models named LTSF-Linear for comparison. Experimental results on nine real-life datasets show that LTSF-Linear surprisingly outperforms existing sophisticated Transformer-based LTSF models in all cases, and often by a large margin. Moreover, we conduct comprehensive empirical studies to explore the impacts of various design elements of LTSF models on their temporal relation extraction capability. We hope this surprising finding opens up new research directions for the LTSF task. We also advocate revisiting the validity of Transformer-based solutions for other time series analysis tasks (e.g., anomaly detection) in the future. Code is available at: \url{https://github.com/cure-lab/LTSF-Linear}.},
archivePrefix = {arXiv},
arxivId = {2205.13504},
author = {Zeng, Ailing and Chen, Muxi and Zhang, Lei and Xu, Qiang},
doi = {10.1609/aaai.v37i9.26317},
eprint = {2205.13504},
file = {:Users/jbejarano/Library/CloudStorage/Dropbox/my_mendeley/Zeng et al. - 2022 - Are Transformers Effective for Time Series Forecasting.pdf:pdf},
isbn = {9781577358800},
issn = {2159-5399},
journal = {Proceedings of the 37th AAAI Conference on Artificial Intelligence, AAAI 2023},
month = {may},
pages = {11121--11128},
publisher = {AAAI Press},
title = {{Are Transformers Effective for Time Series Forecasting?}},
url = {https://arxiv.org/pdf/2205.13504},
volume = {37},
year = {2022}
}
@article{Zhou2020,
abstract = {Many real-world applications require the prediction of long sequence time-series, such as electricity consumption planning. Long sequence time-series forecasting (LSTF) demands a high prediction capacity of the model, which is the ability to capture precise long-range dependency coupling between output and input efficiently. Recent studies have shown the potential of Transformer to increase the prediction capacity. However, there are several severe issues with Transformer that prevent it from being directly applicable to LSTF, including quadratic time complexity, high memory usage, and inherent limitation of the encoder-decoder architecture. To address these issues, we design an efficient transformer-based model for LSTF, named Informer, with three distinctive characteristics: (i) a $ProbSparse$ self-attention mechanism, which achieves $O(L \log L)$ in time complexity and memory usage, and has comparable performance on sequences' dependency alignment. (ii) the self-attention distilling highlights dominating attention by halving cascading layer input, and efficiently handles extreme long input sequences. (iii) the generative style decoder, while conceptually simple, predicts the long time-series sequences at one forward operation rather than a step-by-step way, which drastically improves the inference speed of long-sequence predictions. Extensive experiments on four large-scale datasets demonstrate that Informer significantly outperforms existing methods and provides a new solution to the LSTF problem.},
archivePrefix = {arXiv},
arxivId = {2012.07436},
author = {Zhou, Haoyi and Zhang, Shanghang and Peng, Jieqi and Zhang, Shuai and Li, Jianxin and Xiong, Hui and Zhang, Wancai},
doi = {10.1609/aaai.v35i12.17325},
eprint = {2012.07436},
file = {:Users/jbejarano/Library/CloudStorage/Dropbox/my_mendeley/Zhou et al. - 2020 - Informer Beyond Efficient Transformer for Long Sequence Time-Series Forecasting.pdf:pdf},
isbn = {9781713835974},
issn = {2159-5399},
journal = {35th AAAI Conference on Artificial Intelligence, AAAI 2021},
month = {dec},
pages = {11106--11115},
publisher = {Association for the Advancement of Artificial Intelligence},
title = {{Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting}},
url = {https://arxiv.org/pdf/2012.07436},
volume = {12B},
year = {2020}
}
