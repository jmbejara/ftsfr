{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import ctypes\n",
    "from scipy.interpolate import CubicSpline\n",
    "import os\n",
    "\n",
    "# from merge_bond_treasury_redcode import *\n",
    "from NEW_MERGE_cds_bond import *\n",
    "# from merge_cds_bond import *\n",
    "# from process_final_product import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR = config(\"DATA_DIR\")\n",
    "\n",
    "DATA_DIR = r'../../../FS-project_files'\n",
    "\n",
    "# Initial Pull and analysis\n",
    "TREASURY_ISSUE_FILE_NAME = \"issue_data_mod.parquet\"\n",
    "TREASURY_MONTHLY_FILE_NAME = \"monthly_ts_data_mod.parquet\"\n",
    "CORPORATES_MONTHLY_FILE_NAME = \"corporate_bond_returns.parquet\"\n",
    "RED_CODE_FILE_NAME = \"RED_and_ISIN_mapping.parquet\"\n",
    "\n",
    "# # Secondary Pull and final analysis\n",
    "# BOND_RED_CODE_FILE_NAME = \"merged_bond_treasuries_redcode.parquet\"\n",
    "CDS_FILE_NAME = \"cds_final.pkl\"\n",
    "# FINAL_ANALYSIS_FILE_NAME = \"final_data.parquet\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "treasury_monthly_data = pd.read_parquet(f\"{DATA_DIR}/{TREASURY_MONTHLY_FILE_NAME}\")\n",
    "treasury_issue_data = pd.read_parquet(f\"{DATA_DIR}/{TREASURY_ISSUE_FILE_NAME}\")\n",
    "corp_data = pd.read_parquet(f\"{DATA_DIR}/{CORPORATES_MONTHLY_FILE_NAME}\")\n",
    "red_data = pd.read_parquet(f\"{DATA_DIR}/{RED_CODE_FILE_NAME}\")\n",
    "cds_df = pd.read_pickle(f\"{DATA_DIR}/{CDS_FILE_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kycrspid</th>\n",
       "      <th>kytreasno</th>\n",
       "      <th>mcaldt</th>\n",
       "      <th>tmpubout</th>\n",
       "      <th>tmduratn</th>\n",
       "      <th>tmyld</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19610622.800000</td>\n",
       "      <td>200001.0</td>\n",
       "      <td>1960-10-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>234.0</td>\n",
       "      <td>0.000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19610622.800000</td>\n",
       "      <td>200001.0</td>\n",
       "      <td>1960-11-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.000079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19610622.800000</td>\n",
       "      <td>200001.0</td>\n",
       "      <td>1960-12-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19610622.800000</td>\n",
       "      <td>200001.0</td>\n",
       "      <td>1961-01-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0.000068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19610622.800000</td>\n",
       "      <td>200001.0</td>\n",
       "      <td>1961-02-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          kycrspid  kytreasno      mcaldt  tmpubout  tmduratn     tmyld\n",
       "0  19610622.800000   200001.0  1960-10-31       NaN     234.0  0.000076\n",
       "1  19610622.800000   200001.0  1960-11-30       NaN     204.0  0.000079\n",
       "2  19610622.800000   200001.0  1960-12-30       NaN     174.0  0.000067\n",
       "3  19610622.800000   200001.0  1961-01-31       NaN     142.0  0.000068\n",
       "4  19610622.800000   200001.0  1961-02-28       NaN     114.0  0.000074"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treasury_monthly_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kycrspid</th>\n",
       "      <th>kytreasno</th>\n",
       "      <th>tmatdt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19610622.800000</td>\n",
       "      <td>200001.0</td>\n",
       "      <td>1961-06-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19610623.400000</td>\n",
       "      <td>200002.0</td>\n",
       "      <td>1961-06-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19610629.400000</td>\n",
       "      <td>200003.0</td>\n",
       "      <td>1961-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19610706.400000</td>\n",
       "      <td>200004.0</td>\n",
       "      <td>1961-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19610713.400000</td>\n",
       "      <td>200005.0</td>\n",
       "      <td>1961-07-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          kycrspid  kytreasno      tmatdt\n",
       "0  19610622.800000   200001.0  1961-06-22\n",
       "1  19610623.400000   200002.0  1961-06-23\n",
       "2  19610629.400000   200003.0  1961-06-29\n",
       "3  19610706.400000   200004.0  1961-07-06\n",
       "4  19610713.400000   200005.0  1961-07-13"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treasury_issue_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "treasury_data_combined = merge_treasury_data(treasury_issue_data, treasury_monthly_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kycrspid</th>\n",
       "      <th>kytreasno</th>\n",
       "      <th>mcaldt</th>\n",
       "      <th>tmpubout</th>\n",
       "      <th>tmduratn</th>\n",
       "      <th>tmatdt</th>\n",
       "      <th>treas_yld</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19610622.800000</td>\n",
       "      <td>200001.0</td>\n",
       "      <td>1960-10-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>234.0</td>\n",
       "      <td>1961-06-22</td>\n",
       "      <td>0.028055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19610622.800000</td>\n",
       "      <td>200001.0</td>\n",
       "      <td>1960-11-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>204.0</td>\n",
       "      <td>1961-06-22</td>\n",
       "      <td>0.029241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19610622.800000</td>\n",
       "      <td>200001.0</td>\n",
       "      <td>1960-12-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>174.0</td>\n",
       "      <td>1961-06-22</td>\n",
       "      <td>0.024777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19610622.800000</td>\n",
       "      <td>200001.0</td>\n",
       "      <td>1961-01-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142.0</td>\n",
       "      <td>1961-06-22</td>\n",
       "      <td>0.025169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19610622.800000</td>\n",
       "      <td>200001.0</td>\n",
       "      <td>1961-02-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1961-06-22</td>\n",
       "      <td>0.027243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          kycrspid  kytreasno      mcaldt  tmpubout  tmduratn      tmatdt  \\\n",
       "0  19610622.800000   200001.0  1960-10-31       NaN     234.0  1961-06-22   \n",
       "1  19610622.800000   200001.0  1960-11-30       NaN     204.0  1961-06-22   \n",
       "2  19610622.800000   200001.0  1960-12-30       NaN     174.0  1961-06-22   \n",
       "3  19610622.800000   200001.0  1961-01-31       NaN     142.0  1961-06-22   \n",
       "4  19610622.800000   200001.0  1961-02-28       NaN     114.0  1961-06-22   \n",
       "\n",
       "   treas_yld  \n",
       "0   0.028055  \n",
       "1   0.029241  \n",
       "2   0.024777  \n",
       "3   0.025169  \n",
       "4   0.027243  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treasury_data_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_data = pd.read_parquet(f\"{DATA_DIR}/{CORPORATES_MONTHLY_FILE_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_data = treasury_data_combined.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'cusip', 'issuer_cusip', 'permno', 'exretn_t+1',\n",
       "       'exretnc_bns_t+1', 'exretnc_t+1', 'exretnc_dur_t+1', 'bond_ret_t+1',\n",
       "       'bond_ret', 'exretn', 'exretnc_bns', 'exretnc', 'exretnc_dur', 'rating',\n",
       "       'cs', 'cs_6m_delta', 'bond_yield', 'bond_amount_out', 'offering_amt',\n",
       "       'bondprc', 'perc_par', 'tmt', 'duration', 'ind_num_17', 'sic_code',\n",
       "       'mom6_1', 'ltrev48_12', 'BOND_RET', 'ILLIQ', 'var95', 'n_trades_month',\n",
       "       'size_ig', 'size_jk', 'zcb', 'conv', 'BOND_YIELD', 'CS', 'BONDPRC',\n",
       "       'PRFULL', 'DURATION', 'CONVEXITY', 'CS_6M_DELTA', 'bond_value',\n",
       "       'BOND_VALUE', 'coupon', 'bond_type', 'principal_amt', 'bondpar_mil'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bond_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>issuer_cusip</th>\n",
       "      <th>CS</th>\n",
       "      <th>size_ig</th>\n",
       "      <th>size_jk</th>\n",
       "      <th>tmt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002-08-31</td>\n",
       "      <td>000336</td>\n",
       "      <td>0.032526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002-09-30</td>\n",
       "      <td>000336</td>\n",
       "      <td>0.049044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002-10-31</td>\n",
       "      <td>000336</td>\n",
       "      <td>0.045408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002-11-30</td>\n",
       "      <td>000336</td>\n",
       "      <td>0.039786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002-12-31</td>\n",
       "      <td>000336</td>\n",
       "      <td>0.079508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2003-01-31</td>\n",
       "      <td>000336</td>\n",
       "      <td>0.068708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2003-02-28</td>\n",
       "      <td>000336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2003-03-31</td>\n",
       "      <td>000336</td>\n",
       "      <td>0.090516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2003-04-30</td>\n",
       "      <td>000336</td>\n",
       "      <td>0.068205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2003-05-31</td>\n",
       "      <td>000336</td>\n",
       "      <td>0.060632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.933333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date issuer_cusip        CS  size_ig  size_jk        tmt\n",
       "0 2002-08-31       000336  0.032526      0.0      1.0  70.033333\n",
       "1 2002-09-30       000336  0.049044      0.0      1.0  69.033333\n",
       "2 2002-10-31       000336  0.045408      0.0      1.0  68.000000\n",
       "3 2002-11-30       000336  0.039786      0.0      1.0  67.000000\n",
       "4 2002-12-31       000336  0.079508      0.0      1.0  65.966667\n",
       "5 2003-01-31       000336  0.068708      0.0      1.0  64.933333\n",
       "6 2003-02-28       000336       NaN      NaN      NaN        NaN\n",
       "7 2003-03-31       000336  0.090516      0.0      1.0  62.966667\n",
       "8 2003-04-30       000336  0.068205      0.0      1.0  61.966667\n",
       "9 2003-05-31       000336  0.060632      0.0      1.0  60.933333"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bond_data[['date', 'issuer_cusip', 'CS', 'size_ig', 'size_jk', 'tmt']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     size_jk  size_ig\n",
      "0        1.0      0.0\n",
      "6        NaN      NaN\n",
      "68       0.0      1.0\n",
      "112      1.0      1.0\n"
     ]
    }
   ],
   "source": [
    "unique_pairs_df = bond_data[['size_jk', 'size_ig']].drop_duplicates()\n",
    "print(unique_pairs_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   size_jk  size_ig  unique_cusip_count\n",
      "0      0.0      1.0                2402\n",
      "1      1.0      0.0                9134\n",
      "2      1.0      1.0               19146\n"
     ]
    }
   ],
   "source": [
    "unique_counts = (\n",
    "    bond_data\n",
    "      .groupby(['size_jk', 'size_ig'])['cusip']\n",
    "      .nunique()                        # count distinct CUSIPs\n",
    "      .reset_index(name='unique_cusip_count')\n",
    ")\n",
    "\n",
    "print(unique_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'cusip', 'issuer_cusip', 'permno', 'exretn_t+1',\n",
       "       'exretnc_bns_t+1', 'exretnc_t+1', 'exretnc_dur_t+1', 'bond_ret_t+1',\n",
       "       'bond_ret', 'exretn', 'exretnc_bns', 'exretnc', 'exretnc_dur', 'rating',\n",
       "       'cs', 'cs_6m_delta', 'bond_yield', 'bond_amount_out', 'offering_amt',\n",
       "       'bondprc', 'perc_par', 'tmt', 'duration', 'ind_num_17', 'sic_code',\n",
       "       'mom6_1', 'ltrev48_12', 'BOND_RET', 'ILLIQ', 'var95', 'n_trades_month',\n",
       "       'size_ig', 'size_jk', 'zcb', 'conv', 'BOND_YIELD', 'CS', 'BONDPRC',\n",
       "       'PRFULL', 'DURATION', 'CONVEXITY', 'CS_6M_DELTA', 'bond_value',\n",
       "       'BOND_VALUE', 'coupon', 'bond_type', 'principal_amt', 'bondpar_mil'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bond_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_red_df = merge_red_code_into_bond_treas(bond_data[['date', 'issuer_cusip', 'CS', 'size_ig', 'size_jk', 'tmt']], red_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cds_df = pd.read_pickle(f\"{DATA_DIR}/{}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_cds_into_bonds(bond_red_df, cds_df):\n",
    "    '''\n",
    "    bond_red_df: dataframe with the issuer cusip and red_code now added\n",
    "        date, -- date when data was collected\n",
    "        issuer_cusip, -- cusip of issuing firm\n",
    "        CS, -- Credit Spread we replace Z-spread with\n",
    "        size_ig, -- 0 if no ig bonds in portfolio, 1 if yes\n",
    "        size_jk, -- 0 if no junk bonds in portfolio, 1 if yes\n",
    "        mat_days, -- time to maturity in days\n",
    "        redcode -- redcode is issuer specific, used to merge CDS values later on\n",
    "\n",
    "    cds_df: dataframe containing cds_data\n",
    "        date, -- date of report \n",
    "        'ticker', -- ticker of issuer\n",
    "        'redcode', -- redcode of issuer\n",
    "        'parspread', -- parspread\n",
    "        'tenor', -- tenor, how long\n",
    "        'tier', -- tier of debt\n",
    "        'country', -- country of issuer\n",
    "        'year' -- year of date\n",
    "    \n",
    "    output: dataframe with par spread values merged into all values where there was a possible cubic spline\n",
    "       'cusip', -- unique bond tag\n",
    "       'date', -- reporting date\n",
    "       'mat_days', -- days till maturity\n",
    "       'CS', -- credit spread\n",
    "        'size_ig', -- 0 if no ig bonds in portfolio, 1 if yes\n",
    "        'size_jk', -- 0 if no junk bonds in portfolio, 1 if yes\n",
    "       'par_spread', -- parspread of CDS, backed out by Cubic Spline\n",
    "    '''\n",
    "    date_set = set(bond_red_df.date.unique())\n",
    "    cds_df = cds_df[cds_df['date'].isin(date_set)].dropna(subset=['date', 'parspread', 'tenor', 'redcode'])\n",
    "\n",
    "    # par spread values are roughly consistent for each tenor, make broad assumptions on true value on par spread\n",
    "    c_df_avg = cds_df.groupby(cds_df.columns.difference(['parspread']).tolist(), as_index=False).agg({'parspread': 'median'})\n",
    "\n",
    "    df_unique_count = c_df_avg.groupby(['redcode', 'date'])['tenor'].nunique().reset_index()\n",
    "    df_unique_count.rename(columns={'tenor': 'unique_tenor_count'}, inplace=True)\n",
    "\n",
    "    # need at least 2 for cubic spline\n",
    "    df_unique_count = df_unique_count[df_unique_count['unique_tenor_count'] > 1]\n",
    "\n",
    "    # grab the filtered_cds_df by using df_uni_count as a filter\n",
    "    filtered_cds_df = c_df_avg.merge(df_unique_count[['redcode', 'date']], on=['redcode', 'date'], how='inner')\n",
    "\n",
    "    # my mapping to convert tenor to days to get a rough approximation of a daily spline\n",
    "    tenor_to_days = {\n",
    "        \"1Y\": 365,\n",
    "        \"3Y\": 3 * 365,\n",
    "        \"5Y\": 5 * 365,\n",
    "        \"7Y\": 7 * 365,\n",
    "        \"10Y\": 10 * 365\n",
    "    }\n",
    "\n",
    "    filtered_cds_df['tenor_days'] = filtered_cds_df['tenor'].map(tenor_to_days)\n",
    "\n",
    "    # Dictionary to store cubic splines for each (redcode, date) pair\n",
    "    cubic_splines = {}\n",
    "\n",
    "    # Group by (redcode, date) and create splines\n",
    "    for (redcode, date), group in filtered_cds_df.groupby(['redcode', 'date']):\n",
    "        x = group['tenor_days'].values\n",
    "        y = group['parspread'].values\n",
    "        \n",
    "        sorted_indices = np.argsort(x)\n",
    "        x_sorted, y_sorted = x[sorted_indices], y[sorted_indices]\n",
    "\n",
    "        # Fit cubic spline\n",
    "        try:\n",
    "            cubic_splines[(redcode, date)] = CubicSpline(x_sorted, y_sorted)\n",
    "        except:\n",
    "            print(x_sorted)\n",
    "            print(y_sorted)\n",
    "\n",
    "    # START filtering the bond dataframe to make the merge easier\n",
    "    red_set = set(filtered_cds_df['redcode'].unique())\n",
    "    bond_red_df = bond_red_df[bond_red_df['redcode'].isin(red_set)]\n",
    "\n",
    "\n",
    "    # vectorized function to grab the par spread\n",
    "    def add_par_spread_vectorized(df):\n",
    "        mask = df.set_index(['redcode', 'date']).index.isin(cubic_splines.keys())\n",
    "\n",
    "        # spline interpolation only for matching keys\n",
    "        valid_rows = df.loc[mask]\n",
    "        df.loc[mask, 'par_spread'] = valid_rows.apply(\n",
    "            lambda row: cubic_splines[(row['redcode'], row['date'])](row['mat_days']), axis=1\n",
    "        )\n",
    "\n",
    "        df['par_spread'] = df['par_spread'].fillna(np.nan)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    par_df = add_par_spread_vectorized(bond_red_df)\n",
    "    par_df = par_df.dropna(subset=['par_spread'])\n",
    "\n",
    "    # keep only the important columns\n",
    "    par_df = par_df[['cusip', 'date', 'mat_days', 'CS', 'size_ig', 'size_jk', 'par_spread']]\n",
    "    # have had issues with a phantom array column\n",
    "    def safe_convert(x):\n",
    "        \"\"\"Convert lists and arrays to tuples while keeping other data types unchanged.\"\"\"\n",
    "        if isinstance(x, list):\n",
    "            return tuple(x)\n",
    "        elif isinstance(x, np.ndarray):\n",
    "            return tuple(x.tolist()) if x.ndim > 0 else x.item()  # Convert array to tuple if not scalar\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    # Apply safe conversion\n",
    "    par_df = par_df.applymap(safe_convert)\n",
    "    par_df = par_df.drop_duplicates()\n",
    "\n",
    "    return par_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'maturity'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\xuv14\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'maturity'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmerge_cds_into_bonds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbond_red_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcds_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[44], line 80\u001b[0m, in \u001b[0;36mmerge_cds_into_bonds\u001b[1;34m(bond_red_df, cds_df)\u001b[0m\n\u001b[0;32m     77\u001b[0m bond_red_df \u001b[38;5;241m=\u001b[39m bond_red_df[bond_red_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mredcode\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(red_set)]\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# add days for putting into cubic spline\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m bond_red_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdays\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (\u001b[43mbond_red_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaturity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m-\u001b[39m bond_red_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdays\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# vectorized function to grab the par spread\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21madd_par_spread_vectorized\u001b[39m(df):\n",
      "File \u001b[1;32mc:\\Users\\xuv14\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\xuv14\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'maturity'"
     ]
    }
   ],
   "source": [
    "merge_cds_into_bonds(bond_red_df, cds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
