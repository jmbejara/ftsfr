{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8486efdf",
   "metadata": {},
   "source": [
    "# Portfolio Construction\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecee89cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(1, \"../\")\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from settings import config\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "from scipy.stats import norm, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79ef790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9e5b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro, jarque_bera, normaltest, skew, kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8509d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d0cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2275867f",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = Path(config(\"OUTPUT_DIR\"))\n",
    "DATA_DIR = Path(config(\"DATA_DIR\"))\n",
    "DATA_DIR = DATA_DIR / \"options\"\n",
    "WRDS_USERNAME = config(\"WRDS_USERNAME\")\n",
    "\n",
    "START_DATE_01 = date(1996, 1, 1)\n",
    "END_DATE_01 = date(2012, 1, 31)\n",
    "\n",
    "START_DATE_02 = date(2012, 2, 1)\n",
    "END_DATE_02 = date(2019, 12, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a18448",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_RANGE = f\"{pd.Timestamp(START_DATE_01):%Y-%m}_{pd.Timestamp(END_DATE_02):%Y-%m}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d24def",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e7fee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Black-Scholes elasticity ---\n",
    "def bs_elasticity(S, K, T, r, sigma, option_type=\"call\"):\n",
    "    d1 = (np.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))\n",
    "    if option_type == \"call\":\n",
    "        price = S * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(\n",
    "            d1 - sigma * np.sqrt(T)\n",
    "        )\n",
    "        delta = norm.cdf(d1)\n",
    "    else:\n",
    "        price = K * np.exp(-r * T) * norm.cdf(-d1 + sigma * np.sqrt(T)) - S * norm.cdf(\n",
    "            -d1\n",
    "        )\n",
    "        delta = -norm.cdf(-d1)\n",
    "    return (delta * S / price), price\n",
    "\n",
    "\n",
    "# Gaussian kernel function\n",
    "def kernel_weights(m_grid, ttm_grid, k_s, ttm, bw_m=0.0125, bw_t=10):\n",
    "    m_grid = np.asarray(m_grid, dtype=float)\n",
    "    ttm_grid = np.asarray(ttm_grid, dtype=float)\n",
    "    x = (m_grid - k_s) / bw_m\n",
    "    y = (ttm_grid - ttm) / bw_t\n",
    "    dist_sq = x**2 + y**2\n",
    "    weights = np.exp(-0.5 * dist_sq)\n",
    "    return weights / weights.sum() if weights.sum() > 0 else np.zeros_like(weights)\n",
    "\n",
    "\n",
    "# --- Construct a single day portfolio ---\n",
    "def construct_portfolio(data, k_s_target, ttm_target, option_type=\"call\", r=0.01):\n",
    "    subset = data[(data[\"option_type\"] == option_type)]\n",
    "    weights = kernel_weights(subset[\"moneyness\"], subset[\"ttm\"], k_s_target, ttm_target)\n",
    "    subset = subset.assign(weight=weights)\n",
    "    subset = subset[subset[\"weight\"] > 0.01]\n",
    "    subset[\"weight\"] /= subset[\"weight\"].sum()\n",
    "\n",
    "    # Leverage-adjusted returns\n",
    "    elast, price = bs_elasticity(\n",
    "        S=subset[\"underlying\"],\n",
    "        K=subset[\"strike\"],\n",
    "        T=subset[\"ttm\"] / 365,\n",
    "        r=r,\n",
    "        sigma=subset[\"iv\"],\n",
    "        option_type=option_type,\n",
    "    )\n",
    "    subset[\"leverage_return\"] = subset[\"daily_return\"] / elast\n",
    "\n",
    "    return (subset[\"leverage_return\"] * subset[\"weight\"]).sum()\n",
    "\n",
    "\n",
    "# --- Main Loop (simplified) ---\n",
    "def build_portfolios(option_data, m_grid, ttm_grid, option_types=[\"call\", \"put\"]):\n",
    "    portfolios = []\n",
    "    for opt_type in option_types:\n",
    "        for k_s in m_grid:\n",
    "            for ttm in ttm_grid:\n",
    "                ret = construct_portfolio(option_data, k_s, ttm, option_type=opt_type)\n",
    "                portfolios.append(\n",
    "                    {\"type\": opt_type, \"moneyness\": k_s, \"ttm\": ttm, \"return\": ret}\n",
    "                )\n",
    "    return pd.DataFrame(portfolios)\n",
    "\n",
    "\n",
    "def calc_kernel_weights(spx_mod):\n",
    "    \"\"\"Calculate kernel weights for each option in the SPX dataset based on moneyness and maturity targets.\n",
    "    This function iterates through predefined moneyness and maturity targets, applies kernel weights to candidate options.\"\"\"\n",
    "\n",
    "    # Define moneyness and maturity targets from the paper\n",
    "    moneyness_targets = [0.90, 0.925, 0.950, 0.975, 1.000, 1.025, 1.050, 1.075, 1.100]\n",
    "    maturity_targets = [30, 60, 90]\n",
    "    cp_flags = [\"C\", \"P\"]\n",
    "\n",
    "    # Preprocess base DataFrame\n",
    "    spx_mod[\"days_to_maturity_int\"] = spx_mod[\"days_to_maturity\"].dt.days\n",
    "    spx_mod = spx_mod.reset_index()\n",
    "    spx_mod[\"original_index\"] = spx_mod.index\n",
    "\n",
    "    weight_results = []\n",
    "\n",
    "    # Iterate through each strategy target\n",
    "    for cp_flag in cp_flags:\n",
    "        for target_moneyness in moneyness_targets:\n",
    "            for target_ttm in maturity_targets:\n",
    "                # Filter candidate options\n",
    "                candidate_options = spx_mod[\n",
    "                    (spx_mod[\"cp_flag\"] == cp_flag)\n",
    "                    & (spx_mod[\"moneyness_id\"] == target_moneyness)\n",
    "                    & (spx_mod[\"maturity_id\"] == target_ttm)\n",
    "                ].copy()\n",
    "\n",
    "                if candidate_options.empty:\n",
    "                    continue\n",
    "\n",
    "                candidate_options[\"kernel_weight\"] = np.nan\n",
    "\n",
    "                # Apply kernel weights per date\n",
    "                for date, g in candidate_options.groupby(\"date\"):\n",
    "                    idx = g.index\n",
    "                    weights = kernel_weights(\n",
    "                        g[\"moneyness\"].values,\n",
    "                        g[\"days_to_maturity_int\"].values,\n",
    "                        k_s=target_moneyness,\n",
    "                        ttm=target_ttm,\n",
    "                    )\n",
    "                    candidate_options.loc[idx, \"kernel_weight\"] = weights\n",
    "\n",
    "                weight_results.append(\n",
    "                    candidate_options[[\"original_index\", \"kernel_weight\"]]\n",
    "                )\n",
    "\n",
    "    # Merge weights back into spx_mod\n",
    "    if weight_results:\n",
    "        all_weights = pd.concat(weight_results).set_index(\"original_index\")\n",
    "        spx_mod.set_index(\"original_index\", inplace=True)\n",
    "        spx_mod[\"kernel_weight\"] = all_weights[\"kernel_weight\"]\n",
    "        spx_mod.reset_index(inplace=True)\n",
    "    else:\n",
    "        print(\"No matching options found for any target.\")\n",
    "\n",
    "    spx_mod.drop(columns=[\"original_index\"], inplace=True)\n",
    "    return spx_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b258604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_option_delta_elasticity(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    T = df[\"days_to_maturity\"].dt.days / 365.0\n",
    "    S = df[\"close\"]\n",
    "    K = df[\"strike_price\"]\n",
    "    r = df[\"tb_m3\"] / 100\n",
    "    sigma = df[\"IV\"]\n",
    "    d1 = (np.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))\n",
    "\n",
    "    df = df.assign(\n",
    "        option_delta=np.where(df[\"cp_flag\"] == \"C\", norm.cdf(d1), norm.cdf(d1) - 1),\n",
    "        option_elasticity=lambda x: x[\"option_delta\"] * x[\"close\"] / x[\"mid_price\"],\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a136574f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_option_data(filename):\n",
    "    # Example string interval: '(0.9, 0.95]'\n",
    "    # Remove whitespace and parse the string into tuples\n",
    "    def parse_interval_string(s):\n",
    "        # Handle missing or malformed entries gracefully\n",
    "        if pd.isnull(s) or not isinstance(s, str):\n",
    "            return pd.NA  # or np.nan\n",
    "        s = s.strip().replace(\"(\", \"\").replace(\"]\", \"\")\n",
    "        try:\n",
    "            left, right = map(float, s.split(\",\"))\n",
    "            return pd.Interval(left, right, closed=\"right\")\n",
    "        except ValueError:\n",
    "            return pd.NA\n",
    "\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    # restore the 'moneyness_bin' column as intervals\n",
    "    df[\"moneyness_bin\"] = df[\"moneyness_bin\"].apply(parse_interval_string)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f974e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cjs_return_leverage_investment(spx_mod):\n",
    "    df = spx_mod.copy()\n",
    "    df = df.sort_values([\"ftfsa_id\", \"date\"])\n",
    "\n",
    "    # Lag price\n",
    "    df[\"mid_price_lag\"] = df.groupby(\"ftfsa_id\")[\"mid_price\"].shift(1)\n",
    "\n",
    "    # Return and daily risk-free rate\n",
    "    df[\"option_return\"] = (df[\"mid_price\"] - df[\"mid_price_lag\"]) / df[\"mid_price_lag\"]\n",
    "    df[\"daily_rf\"] = df[\"tb_m3\"] / 100 / 252\n",
    "\n",
    "    # Weighted dollar investment and return contribution\n",
    "    df[\"inv_weight\"] = df[\"kernel_weight\"] / df[\"option_elasticity\"]\n",
    "    df[\"inv_return\"] = df[\"inv_weight\"] * df[\"option_return\"]\n",
    "\n",
    "    # Group and aggregate\n",
    "    grouped = df.groupby([\"date\", \"ftfsa_id\"])\n",
    "\n",
    "    port = grouped.agg(\n",
    "        total_inv_weight=(\"inv_weight\", \"sum\"),\n",
    "        total_inv_return=(\"inv_return\", \"sum\"),\n",
    "        daily_rf=(\"daily_rf\", \"first\"),\n",
    "        cp_flag=(\"cp_flag\", \"first\"),\n",
    "    ).reset_index()\n",
    "\n",
    "    # Apply CJS logic\n",
    "    def adjusted_return(row):\n",
    "        if row[\"cp_flag\"] == \"C\":\n",
    "            return (\n",
    "                row[\"total_inv_return\"]\n",
    "                + (1 - row[\"total_inv_weight\"]) * row[\"daily_rf\"]\n",
    "            )\n",
    "        elif row[\"cp_flag\"] == \"P\":\n",
    "            return (\n",
    "                -row[\"total_inv_return\"]\n",
    "                + (1 + row[\"total_inv_weight\"]) * row[\"daily_rf\"]\n",
    "            )\n",
    "        else:\n",
    "            return np.nan\n",
    "\n",
    "    port[\"portfolio_return\"] = port.apply(adjusted_return, axis=1)\n",
    "\n",
    "    return port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5348f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute normality metrics\n",
    "def normality_summary(df):\n",
    "    summary = []\n",
    "    for col in df.columns:\n",
    "        series = df[col].dropna()\n",
    "        shapiro_p = shapiro(series)[1]\n",
    "        jb_stat, jb_p = jarque_bera(series)\n",
    "        normaltest_p = normaltest(series)[1]\n",
    "        skew_val = skew(series)\n",
    "        kurt_val = kurtosis(series, fisher=False)\n",
    "        summary.append(\n",
    "            {\n",
    "                \"Series\": col,\n",
    "                \"Shapiro_p\": shapiro_p,\n",
    "                \"JarqueBera_p\": jb_p,\n",
    "                \"Normaltest_p\": normaltest_p,\n",
    "                \"Skewness\": skew_val,\n",
    "                \"Kurtosis\": kurt_val,\n",
    "            }\n",
    "        )\n",
    "    return pd.DataFrame(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d27b04",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49448064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read filtered data\n",
    "source_file = Path(DATA_DIR / f\"spx_filtered_final_{DATE_RANGE}.parquet\")\n",
    "spx_filtered = read_option_data(filename=source_file)\n",
    "spx_filtered = spx_filtered.reset_index()\n",
    "\n",
    "# create the moneyness ID from the moneyness_bin column, using the right edge of the interval\n",
    "spx_filtered[\"moneyness_id\"] = spx_filtered[\"moneyness_bin\"].apply(\n",
    "    lambda x: x.right if pd.notnull(x) else np.nan\n",
    ")\n",
    "# drop any rows where moneyness_id is NaN\n",
    "spx_filtered = spx_filtered.dropna(subset=[\"moneyness_id\"])\n",
    "\n",
    "spx_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5fc146",
   "metadata": {},
   "source": [
    "### Construction of Monthly Leverage-Adjusted Portfolio Returns in CJS\n",
    "\n",
    "**Process**\n",
    "\n",
    "The construction of the 27 call and 27 put portfolios in CJS is a multi-step process, with the objective of developing portfolio returns series that are stationary and only moderately skewed. Note that the discrete bucketing of moneyness and days to maturity lead to multiple candidate options for each portfolio on each trading day. These options  are given weights according to a **bivariate Gaussian weighting kernel** in moneyness and maturity (bandwidths: *0.0125 in moneyness* and *10 days to maturity*).\n",
    "\n",
    "Each portfolio's daily returns are initially calculated as simple arithmetic return, assuming the option is bought and sold at its bid-ask midpoint at each rebalancing. The one-day arithmetic return is then converted to a **leverage-adjusted return**. This procedure is achieved by calculating the one-day return of a hypothetical portfolio with $\\omega_{BSM}^{-1}$ dollars invested in the option, and $(1 - \\omega^{-1})$ dollars invested in the risk-free rate, where $\\omega_{BSM}$ is the BSM elasticity based on the implied volatility of the option. \n",
    "\n",
    "\\begin{align}\n",
    "\\omega_{\\text{BSM, Call}} &= \\frac{\\partial C_{\\text{BSM}}}{\\partial S} \\cdot \\frac{S}{C_{\\text{BSM}}} > 1 \\\\\n",
    "\\omega_{\\text{BSM, Put}}  &= \\frac{\\partial P_{\\text{BSM}}}{\\partial S} \\cdot \\frac{S}{P_{\\text{BSM}}} < -1\n",
    "\\end{align}\n",
    "\n",
    "Each **leverage-adjusted call portfolio** comprises of a long position in a fraction of a call, and some investment in the risk-free rate. \n",
    "\n",
    "Each **leverage-adjusted put portfolio** comprises of a short position in a fraction of a put, and >100% investment in the risk-free rate. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3888210a",
   "metadata": {},
   "source": [
    "### Mathematical Details of Portfolio Construction\n",
    "\n",
    "<font color=\"blue\">*For clarity, we present below the mathematics behind CJS' descriptions of the portfolio construction process. The following applies for a single trading day $t$, for a set of candidate call or put options. Portfolios in CJS are identified by 3 characteristics: option type (call or put), moneyness (9 discrete targets), and time to maturity (3 discrete targets). On any given day, it is rare to find options that exactly match the moneyness and maturity targets. Instead, there may be multiple options that are \"close to\" the target moneyness / maturity (each a **\"candidate option\"**). Furthermore, each candidate option has its own price and price sensitivity to changes in the underlying SPX index level. In order to arrive at a \"price\" for an option portfolio, CJS applies a **Gaussian weighting kernel** in moneyness and maturity, as described below. This kernel-weighted price across the candidate options on a given day is used as the price of the **option component** of the portfolio (the other component being the risk-free rate). This portfolio is leverage-adjusted using the BSM elasticity, in order to standardize the sensitivity of OTM and ITM portfolios to changes in the underlying.*</font>\n",
    "\n",
    "#### 1. Gaussian Kernel Weighting\n",
    "\n",
    "Let:\n",
    "\n",
    "* $m_{i}$ = moneyness of option $i$\n",
    "* $\\tau_{i}$ = days to maturity of option $i$\n",
    "* $k_{s}$ = target moneyness\n",
    "* $\\tau$ = target maturity\n",
    "* $h_{m}$, $h_{\\tau}$ = bandwidths for moneyness and maturity\n",
    "* $d_{i}^2 = \\left( \\frac{m_{i} - k_{s}}{h_{m}} \\right)^2 + \\left( \\frac{\\tau_{i} - \\tau}{h_{\\tau}} \\right)^2$\n",
    "\n",
    "Then the unnormalized Gaussian weight for option $i$ is:\n",
    "\n",
    "$$\n",
    "w_{i}^* = \\exp\\left( -\\frac{1}{2} d_{i}^2 \\right)\n",
    "$$\n",
    "\n",
    "The normalized kernel weight:\n",
    "\n",
    "$$\n",
    "w_{i} = \\frac{w_{i}^*}{\\sum_j w_j^*}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Option Elasticity\n",
    "\n",
    "Let:\n",
    "\n",
    "* $S_{t}$ = underlying index level at time $t$\n",
    "* $P_{i}$ = price of option $i$\n",
    "* $\\Delta_{i}$ = option delta\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\n",
    "\\varepsilon_{i} = \\frac{S_t \\cdot \\Delta_{i}}{P_{i}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Arithmetic Return of Option $i$\n",
    "\n",
    "Let:\n",
    "\n",
    "* $P_{i,t-1}$ = price of option $i$ at time $t-1$\n",
    "* $P_{i,t}$ = price of option $i$ at time $t$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\n",
    "r_{i} = \\frac{P_{i,t} - P_{i,t-1}}{P_{i,t-1}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Leverage-Adjusted Portfolio Construction\n",
    "\n",
    "Let:\n",
    "\n",
    "* $r_{f}$ = risk-free rate on day $t$\n",
    "\n",
    "The leverage-adjusted return of the call portfolio is:\n",
    "\n",
    "$$\n",
    "R_t^{call} = \\sum_{i} w_{i} \\cdot \\frac{1}{\\varepsilon_{i}} \\cdot r_{i} + \\left(1 - \\sum_{i} w_{i} \\cdot \\frac{1}{\\varepsilon_{i}} \\right) \\cdot r_f\n",
    "$$\n",
    "\n",
    "The leverage-adjusted return of the put portfolio is:\n",
    "\n",
    "$$\n",
    "R_t^{put} = -\\sum_{i} w_{i} \\cdot \\frac{1}{\\varepsilon_{i}} \\cdot r_{i} + \\left(1 + \\sum_{i} w_{i} \\cdot \\frac{1}{\\varepsilon_{i}} \\right) \\cdot r_f\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f8261f",
   "metadata": {},
   "source": [
    "Below we implement this process. \n",
    "### Implementation\n",
    "#### 1. Build the FTSFA ID for each portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd99c52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the maturity ID based on the closest maturity to 30, 60, or 90 days\n",
    "maturity_id = pd.concat(\n",
    "    (\n",
    "        abs(spx_filtered[\"days_to_maturity\"].dt.days - 30),\n",
    "        abs(spx_filtered[\"days_to_maturity\"].dt.days - 60),\n",
    "        abs(spx_filtered[\"days_to_maturity\"].dt.days - 90),\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "maturity_id.columns = [30, 60, 90]\n",
    "spx_filtered[\"maturity_id\"] = maturity_id.idxmin(axis=1)\n",
    "spx_filtered[\"ftfsa_id\"] = (\n",
    "    spx_filtered[\"cp_flag\"]\n",
    "    + \"_\"\n",
    "    + (spx_filtered[\"moneyness_id\"] * 1000).apply(\n",
    "        lambda x: str(int(x)) if pd.notnull(x) and x == int(x) else str(x)\n",
    "    )\n",
    "    + \"_\"\n",
    "    + spx_filtered[\"maturity_id\"].astype(str)\n",
    ")\n",
    "\n",
    "# set index to ftfsa_id and date\n",
    "spx_filtered.set_index([\"ftfsa_id\", \"date\"], inplace=True)\n",
    "spx_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27198ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_ids = spx_filtered.index.get_level_values(\"ftfsa_id\").unique()\n",
    "portfolio_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861e2549",
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_filtered[\"days_to_maturity\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbb1357",
   "metadata": {},
   "source": [
    "#### 2. Calculate option elasticity and daily kernel weighting for candidate options for each portfolio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2223d006",
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_mod = spx_filtered.copy()\n",
    "\n",
    "# calculate option delta and elasticity\n",
    "spx_mod = calc_option_delta_elasticity(spx_mod)\n",
    "# calculate daily kernel weights for candidate options\n",
    "spx_mod = calc_kernel_weights(spx_mod)\n",
    "spx_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8c6092",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Kernel weight check: All portfolios should sum to 1.0.\")\n",
    "spx_mod.groupby([\"date\", \"ftfsa_id\"])[\"kernel_weight\"].sum().round(15).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66031a9",
   "metadata": {},
   "source": [
    "#### 3. Remove options from the portfolio with weights lower than 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf54218",
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_mod = spx_mod[spx_mod[\"kernel_weight\"] >= 0.01].reset_index(drop=True)\n",
    "spx_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a3d773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check elasticity > 1 for call options and < -1 for put options\n",
    "print(\"Elasticity > 1 for call options?\")\n",
    "spx_mod[spx_mod[\"cp_flag\"] == \"C\"][\"option_elasticity\"].describe()[\"min\"] > 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbf2d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Elasticity < -1 for put options?\")\n",
    "spx_mod[spx_mod[\"cp_flag\"] == \"P\"][\"option_elasticity\"].describe()[\"max\"] < -1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cde7b6",
   "metadata": {},
   "source": [
    "#### 4. Calculate the daily arithmetic return and the leverage-adjusted return of each portfolio. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed923b94",
   "metadata": {},
   "source": [
    "On each trading day, the return of a portfolio is calculated as the <u>weighted average return of the set of candidate options that comprise a single day's option portfolio</u>. The weighting used is the Gaussian kernel weight calculated earlier. Thus the daily return from period $t$ to $t+1$ represents the return from holding a set of candidate options, weighted using the kernel weights as of $t$, from period $t$ to $t+1$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cddac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_returns = compute_cjs_return_leverage_investment(spx_mod)\n",
    "\n",
    "# Preview result\n",
    "portfolio_returns.set_index([\"date\", \"ftfsa_id\"], inplace=True)\n",
    "\n",
    "portfolio_returns = portfolio_returns.pivot_table(\n",
    "    index=\"date\", columns=\"ftfsa_id\", values=\"portfolio_return\"\n",
    ")\n",
    "# daily_returns = pd.DataFrame(np.where(portfolio_returns > 1.0, np.nan, portfolio_returns), index=portfolio_returns.index, columns=portfolio_returns.columns)\n",
    "daily_returns = portfolio_returns.copy()\n",
    "daily_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6447691c",
   "metadata": {},
   "source": [
    "#### 5. (to be implemented) Filling NaNs\n",
    "CJS implement an multi-step process to deal with options with missing prices (detailed in section **1.3 Portfolio Formation** of the paper). We reserve the implementation this NaN-filling process for a future version of this dataset. For the current version, we compound the daily portfolio returns into monthly returns, which is the final form of the data utilized in the paper.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e3774b",
   "metadata": {},
   "source": [
    "#### 6. Compound Daily Portfolio Returns to Monthly (final 54 portfolios in CJS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76c36e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cjs_returns = daily_returns.resample(\"M\").apply(lambda x: (1 + x).prod() - 1)\n",
    "cjs_returns = cjs_returns.reset_index().melt(\n",
    "    id_vars=\"date\", var_name=\"ftfsa_id\", value_name=\"return\"\n",
    ")\n",
    "cjs_returns[\"ftfsa_id\"] = \"cjs_\" + cjs_returns[\"ftfsa_id\"]\n",
    "cjs_returns = cjs_returns[[\"ftfsa_id\", \"date\", \"return\"]].set_index(\n",
    "    [\"ftfsa_id\", \"date\"]\n",
    ")\n",
    "# save to data directory\n",
    "cjs_returns.to_parquet(\n",
    "    DATA_DIR / f\"cjs_portfolio_returns_{DATE_RANGE}.parquet\", index=True\n",
    ")\n",
    "cjs_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6819ebee",
   "metadata": {},
   "source": [
    "## Construction of 18 Portfolio Return Series in He, Kelly, Manela (HKM 2017)\n",
    "\n",
    "*HKM 2017* reduces the 54 portfolio return series constructed in CJS to 18 by taking an equal-weight average across the 3 maturities for the CJS portfolios with the same moneyness. Below we implement that procedure to obtain the final return series for the FTSFA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47b7008",
   "metadata": {},
   "outputs": [],
   "source": [
    "hkm_returns = cjs_returns.copy().reset_index()\n",
    "hkm_returns = hkm_returns.assign(\n",
    "    type=hkm_returns[\"ftfsa_id\"].apply(lambda x: x.split(\"_\")[1]),\n",
    "    moneyness_id=hkm_returns[\"ftfsa_id\"].apply(lambda x: x.split(\"_\")[2]),\n",
    "    maturity_id=hkm_returns[\"ftfsa_id\"].apply(lambda x: x.split(\"_\")[3]),\n",
    ")\n",
    "hkm_returns.drop(columns=[\"ftfsa_id\"], inplace=True)\n",
    "hkm_returns.set_index([\"date\", \"type\", \"moneyness_id\", \"maturity_id\"], inplace=True)\n",
    "hkm_returns = hkm_returns.groupby([\"date\", \"type\", \"moneyness_id\"]).mean()\n",
    "hkm_returns[\"ftfsa_id\"] = (\n",
    "    \"hkm_\"\n",
    "    + hkm_returns.index.get_level_values(\"type\")\n",
    "    + \"_\"\n",
    "    + hkm_returns.index.get_level_values(\"moneyness_id\")\n",
    ")\n",
    "hkm_returns = (\n",
    "    hkm_returns.reset_index()\n",
    "    .drop(columns=[\"type\", \"moneyness_id\"])\n",
    "    .set_index([\"ftfsa_id\", \"date\"])\n",
    "    .sort_index()\n",
    ")\n",
    "# save to data directory\n",
    "hkm_returns.to_parquet(\n",
    "    DATA_DIR / f\"hkm_portfolio_returns_{DATE_RANGE}.parquet\", index=True\n",
    ")\n",
    "hkm_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138a50be",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e098099b",
   "metadata": {},
   "source": [
    "## Data Discussion "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f97a87",
   "metadata": {},
   "source": [
    "***Note:** Code below is for testing and discussion, not final publication.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debe0f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = hkm_returns.copy()\n",
    "# test_data = cjs_returns.copy()\n",
    "\n",
    "test_data = test_data.reset_index().pivot_table(\n",
    "    columns=\"ftfsa_id\", index=\"date\", values=\"return\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cefbe61",
   "metadata": {},
   "source": [
    "### Tests for Normality of Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1eac58",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_df = test_data.copy()\n",
    "\n",
    "# Apply to returns dataframe\n",
    "summary_df = normality_summary(returns_df)\n",
    "display(summary_df.style.format(na_rep=\"NaN\", precision=2))\n",
    "\n",
    "# Plot histogram and QQ plot for each series\n",
    "for col in returns_df.columns:\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    sns.histplot(returns_df[col].dropna(), kde=True, stat=\"density\", bins=30, ax=axs[0])\n",
    "    axs[0].set_title(f\"Histogram with KDE: {col}\")\n",
    "\n",
    "    stats.probplot(returns_df[col].dropna(), dist=\"norm\", plot=axs[1])\n",
    "    axs[1].set_title(f\"Q-Q Plot: {col}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db765f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot groups of portfolios as line charts\n",
    "portfolio_list = []  # ['hkm_C_1000', 'hkm_P_1000'],['cjs_P_950_30', 'cjs_P_1025_60', 'cjs_C_1000_90']\n",
    "\n",
    "chart_data = test_data[portfolio_list] if portfolio_list else test_data\n",
    "\n",
    "chart_data.plot(figsize=(16, 6), title=\"Portfolio Returns Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.gca().grid(True, which=\"major\", color=\"#dddddd\", linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daaf006",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"mean\"\n",
    "chart_data.describe().T[metric].plot(\n",
    "    kind=\"bar\", figsize=(16, 6), title=f\"{metric} for leverage adj returns\"\n",
    ")\n",
    "plt.gca().grid(True, which=\"major\", color=\"#dddddd\", linewidth=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75c60c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_data.isna().sum() / test_data.shape[0]).plot(\n",
    "    kind=\"bar\",\n",
    "    color=\"lightblue\",\n",
    "    figsize=(16, 6),\n",
    "    title=\"Percentage of Missing Returns by Portfolio\",\n",
    ")\n",
    "plt.gca().grid(True, which=\"major\", color=\"#dddddd\", linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863f622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.skew().plot(kind=\"bar\").set_title(\"Portfolio Returns Skewness\")\n",
    "plt.xlabel(\"Portfolio\")\n",
    "plt.xticks(np.arange(len(test_data.columns)), test_data.columns, rotation=90)\n",
    "plt.gca().grid(True, which=\"major\", color=\"#dddddd\", linewidth=1)\n",
    "plt.gcf().set_size_inches(16, 6)\n",
    "plt.ylabel(\"Skewness\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19214049",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.kurtosis().plot(kind=\"bar\").set_title(\"Portfolio Returns Kurtosis\")\n",
    "plt.xlabel(\"Portfolio\")\n",
    "plt.xticks(np.arange(len(test_data.columns)), test_data.columns, rotation=90)\n",
    "plt.gca().grid(True, which=\"major\", color=\"#dddddd\", linewidth=1)\n",
    "plt.gcf().set_size_inches(16, 6)\n",
    "plt.ylabel(\"Kurtosis\")\n",
    "# plt.yscale('log')  # Log scale for better visibility\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c6cab9",
   "metadata": {},
   "source": [
    "### Testing NaN-filling logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e7cbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = spx_mod.set_index([\"date\", \"ftfsa_id\"])\n",
    "test.sort_index(inplace=True)\n",
    "_cols = [\"moneyness\", \"days_to_maturity_int\", \"kernel_weight\", \"exdate\"]\n",
    "test = test[_cols + [_ for _ in test.columns if _ not in _cols]]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36df379",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618e1bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[pd.IndexSlice[\"1996-01-04\":\"1996-01-10\", \"C_1000_30\"], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068a076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[pd.IndexSlice[\"1996-01-04\":\"1996-01-10\", \"C_1025_30\"], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d695eea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25557c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
