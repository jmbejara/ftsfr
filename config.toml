[cache]
# If use_cache is True, then the pull step for all data sources will be skipped in dodo.py
use_cache = false

[data_sources]

## Public data sets. No subscription needed, no api key needed.
# Set to true to download the data
fed_yield_curve = true
he_kelly_manela = true
ken_french_data_library = true
nyu_call_report = true
open_source_bond = true

## Subscription data sets. Subscription needed, api key needed.
# Set to false if subscription is available, data will be pulled from source
bloomberg_terminal = true
wrds_bank_premium = true
wrds_bond_returns = true
wrds_compustat = true
wrds_crsp = true
wrds_crsp_compustat = true
wrds_datastream = true
wrds_fx = true
wrds_markit = true
wrds_mergent = true
wrds_optionmetrics = true

[models]
# Statistical Models (LocalForecastingModel)
arima = true  # ARIMA - Autoregressive Integrated Moving Average model
ets = false  # ETS - Exponential Smoothing (Error, Trend, Seasonal) state space model
simple_exponential_smoothing = true  # Simple Exponential Smoothing - basic smoothing for level-only data
tbats = false  # TBATS - Exponential smoothing with Box-Cox transformation, ARMA errors, Trend and Seasonal
theta = false  # Theta Method - simple decomposition method that performs well on M3 competition
prophet = false  # Prophet - Facebook's additive model for time series with strong seasonal effects

# Regression Models (GlobalForecastingModel)
pr = false  # Polynomial Regression - fits polynomial functions to capture non-linear trends
catboost = false  # CatBoost - gradient boosting optimized for categorical features and ordered data

# PyTorch (Lightning)-based Models (GlobalForecastingModel)
# Basic Neural Networks
ffnn = false  # Feed-Forward Neural Network - simple fully connected network for time series
deepar = false  # DeepAR - Amazon's probabilistic RNN for forecasting with uncertainty estimates
wavenet = false  # WaveNet - dilated causal convolutions originally for audio generation

# Linear Models (LTSF-Linear family)
dlinear = false  # D-Linear - decomposition-based linear model for long-term forecasting
nlinear = false  # N-Linear - normalization-based linear model handling distribution shifts

# N-BEATS/N-HiTS family
nbeats = false  # N-BEATS - Neural Basis Expansion Analysis for interpretable forecasting
nhits = false  # N-HiTS - Neural Hierarchical Interpolation for long-horizon forecasting

# Transformer Models
transformer = false  # Transformer - vanilla transformer architecture adapted for time series
autoformer = false  # Autoformer - Auto-Correlation decomposition transformer
informer = false  # Informer - ProbSparse self-attention for efficient long sequence forecasting
patchtst = false  # PatchTST - channel-independent patching for multivariate time series
temporal_fusion_transformer = false  # TFT - Temporal Fusion Transformer with interpretable insights

# Other Advanced Models
tide = false  # TiDE - Time Series Dense Encoder using residual blocks without attention
timesfm = false  # TimesFM - Google's foundation model pre-trained on 100B timepoints

[reports]
is_latex_installed = true
